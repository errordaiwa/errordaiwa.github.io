{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/images/storm.gif","path":"images/storm.gif","modified":0,"renderable":0},{"_id":"source/images/storm-simple.png","path":"images/storm-simple.png","modified":0,"renderable":0},{"_id":"source/images/Models.png","path":"images/Models.png","modified":0,"renderable":0},{"_id":"source/images/storm-messaging.png","path":"images/storm-messaging.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"8d332f22a93a80b5e86a391b5c82f95332fde1d8","modified":1546968907300},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1514806389000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1514806389000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1514806389000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1514806389000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1514806389000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1514806389000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1514806389000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1514806389000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1514806389000},{"_id":"themes/next/README.cn.md","hash":"58ffe752bc4b7f0069fcd6304bbc2d5ff7b80f89","modified":1514806389000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1514806389000},{"_id":"themes/next/README.md","hash":"898213e66d34a46c3cf8446bf693bd50db0d3269","modified":1514806389000},{"_id":"themes/next/_config.yml","hash":"5ff37e90e4d6812c8fc40c03fa6e1d903d743470","modified":1514806389000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1514806389000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1514806389000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1514806389000},{"_id":"source/_posts/dns_config_problem.md","hash":"00dce245a80616ca12259a710e4966773fbdffe3","modified":1546966669290},{"_id":"source/_posts/docker-swarm-mode.md","hash":"6d690f80bb33a4bcc67a1aed85c63d0f8759c026","modified":1546966669290},{"_id":"source/_posts/storm-cpu-overload.md","hash":"36fb665d86d0069677eb8f7be29ed9b552665d77","modified":1546966669291},{"_id":"source/images/storm.gif","hash":"1533aa479747a407e697eccf16568f9e6a3b7539","modified":1546966669295},{"_id":"source/images/storm-simple.png","hash":"745474b9fcd564aafc697572db3285c6dd3fcc7e","modified":1546966669295},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1514806389000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1514806389000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1514806389000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1514806389000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1514806389000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1514806389000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1514806389000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1514806389000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1514806389000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1514806389000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1514806389000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1514806389000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1514806389000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1514806389000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1514806389000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1514806389000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1514806389000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1514806389000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1514806389000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1514806389000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1514806389000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1514806389000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1514806389000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1514806389000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1514806389000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1514806389000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1514806389000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1514806389000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1514806389000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1514806389000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1514806389000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1514806389000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1514806389000},{"_id":"source/images/Models.png","hash":"561eb92f5275fa514b6ab9d7fc2f46421ff96077","modified":1546966669292},{"_id":"source/images/storm-messaging.png","hash":"04f327c6d9195d89d0d90d8695fac20314115a39","modified":1546966669294},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514806389000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514806389000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1514806389000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1514806389000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1514806389000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1514806389000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1514806389000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1514806389000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1514806389000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1514806389000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1514806389000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1514806389000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1514806389000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1514806389000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1514806389000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1514806389000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1514806389000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1514806389000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1514806389000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1514806389000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1514806389000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1514806389000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1514806389000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1514806389000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1514806389000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1514806389000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1514806389000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1514806389000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1514806389000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1514806389000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1514806389000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1514806389000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1514806389000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1514806389000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1514806389000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1514806389000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1514806389000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1514806389000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1514806389000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1514806389000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1514806389000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1514806389000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1514806389000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1514806389000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1514806389000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1514806389000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1514806389000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514806389000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1514806389000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514806389000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1514806389000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1514806389000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1514806389000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514806389000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1514806389000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1514806389000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1514806389000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1514806389000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1514806389000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1514806389000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1514806389000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1514806389000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1514806389000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1514806389000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514806389000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1514806389000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1514806389000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1514806389000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1514806389000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1514806389000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1514806389000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1514806389000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1514806389000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1514806389000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1514806389000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1514806389000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1514806389000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1514806389000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1514806389000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1514806389000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1514806389000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1514806389000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1514806389000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1514806389000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1514806389000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1514806389000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1514806389000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1514806389000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1514806389000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1514806389000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1514806389000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1514806389000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1514806389000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1514806389000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1514806389000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1514806389000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1514806389000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1514806389000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1514806389000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1514806389000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1514806389000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1514806389000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1514806389000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1514806389000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1514806389000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1514806389000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1514806389000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1514806389000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1514806389000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1514806389000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1514806389000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514806389000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1514806389000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1514806389000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1514806389000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1514806389000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1514806389000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1514806389000},{"_id":"public/archives/index.html","hash":"3b6b9332cc664230b5e8d7489f4d306b5de5752a","modified":1546969596498},{"_id":"public/archives/2015/index.html","hash":"a0008835a737bfe662ab0ab6654399f48b3fbc49","modified":1546969596498},{"_id":"public/archives/2015/07/index.html","hash":"604e375a7153fae6692c10a6b95753c1440bc69a","modified":1546969596498},{"_id":"public/archives/2016/index.html","hash":"e11d550de54fa5bd4c7daf686144e581305e88f8","modified":1546969596498},{"_id":"public/archives/2016/12/index.html","hash":"8c0138c4d1b0bb2c7c55a4a6802cf56cba21d0fd","modified":1546969596498},{"_id":"public/archives/2018/index.html","hash":"dd4612c210918f8fb42856e4e4914464ed2cf0ea","modified":1546969596498},{"_id":"public/archives/2018/08/index.html","hash":"5dd7143b793bbdd34cc889487f9f2593e797aeeb","modified":1546969596498},{"_id":"public/categories/Tech/index.html","hash":"3d22959b747f1a791717d5f527c4a4bd260c2d47","modified":1546969596499},{"_id":"public/tags/DNS/index.html","hash":"60bf4e5bd7d68640e2cc1e14ecc0b18ee53a08dc","modified":1546969596499},{"_id":"public/tags/Docker/index.html","hash":"730644746b8b468c820455c21308c096b90bcd18","modified":1546969596499},{"_id":"public/tags/Problem/index.html","hash":"414cc29dd2d6a764cd4a1664d0f42b68ec87860d","modified":1546969596499},{"_id":"public/tags/Swarm/index.html","hash":"abc8fcff2e43073d8a96383ad7ad2718b6d9d1d7","modified":1546969596499},{"_id":"public/tags/Storm/index.html","hash":"66ed007913831cbabfe36084ad6950f1cf57cd6f","modified":1546969596499},{"_id":"public/2018/08/09/dns_config_problem/index.html","hash":"b9d2e822f0de176d90a16f73785ddac1643f9b67","modified":1546969596499},{"_id":"public/2016/12/14/docker-swarm-mode/index.html","hash":"4fbb242cbaa186439bfb2aee6867e4d172a65144","modified":1546969596499},{"_id":"public/2015/07/18/storm-cpu-overload/index.html","hash":"7b34042ca68ff757216d2bbf6cb89a7a28c0fc04","modified":1546969596499},{"_id":"public/index.html","hash":"246b48caaf06557fe958a2a59621d95eac2242ae","modified":1546969596499},{"_id":"public/CNAME","hash":"8d332f22a93a80b5e86a391b5c82f95332fde1d8","modified":1546969596505},{"_id":"public/images/storm.gif","hash":"1533aa479747a407e697eccf16568f9e6a3b7539","modified":1546969596505},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1546969596505},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1546969596506},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1546969596506},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1546969596506},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1546969596506},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1546969596506},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1546969596506},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1546969596506},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1546969596506},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1546969596506},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1546969596506},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1546969596506},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1546969596506},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1546969596506},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1546969596506},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1546969596506},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1546969596506},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1546969596506},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1546969596506},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1546969596507},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1546969596507},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1546969596507},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1546969596507},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1546969596507},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1546969596507},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1546969596507},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1546969596922},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1546969596507},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1546969596507},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1546969596507},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1546969596507},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1546969596507},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1546969596507},{"_id":"public/css/prism.css","hash":"9ff88ae307098176655ee460023e68ac80358ef4","modified":1546969596507},{"_id":"public/images/storm-simple.png","hash":"745474b9fcd564aafc697572db3285c6dd3fcc7e","modified":1546969596505},{"_id":"public/images/storm-messaging.png","hash":"04f327c6d9195d89d0d90d8695fac20314115a39","modified":1546969596917},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1546969596923},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1546969596930},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1546969596930},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1546969596931},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1546969596931},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1546969596931},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1546969596931},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1546969596931},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1546969596931},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1546969596931},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1546969596932},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1546969596932},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1546969596932},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1546969596932},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1546969596932},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1546969596932},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1546969596932},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1546969596932},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1546969596932},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1546969596933},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1546969596933},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1546969596933},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1546969596933},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1546969596933},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1546969596933},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1546969596933},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1546969596933},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1546969596933},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1546969596933},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1546969596933},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1546969596933},{"_id":"public/css/main.css","hash":"b5d3a79b2896ffcd4427f2bb34a8e6ebd6f75fec","modified":1546969596933},{"_id":"public/images/Models.png","hash":"561eb92f5275fa514b6ab9d7fc2f46421ff96077","modified":1546969596933},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1546969596923},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1546969596933},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1546969596942},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1546969596941},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1546969596941},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1546969596942},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1546969596942},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1546969596942},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1546969596942},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1546969596942},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1546969596942},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1546969596946},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1546969596947},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1546969596933},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1546969596952},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1546969596952},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1546969596967},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1546969596965},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1546969596964},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1546969596967},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1546969596967},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1546969596967},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1546969596967},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1546969596973},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1546969596973},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1546969596974},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1546969596981},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1546969596997},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1546969596997},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1546969597000},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1546969597005},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1546969597018},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1546969597023}],"Category":[{"name":"Tech","_id":"cjqo1fwqp00012kfyukm1pocr"}],"Data":[],"Page":[],"Post":[{"title":"DNS 配置有误导致监控误报的问题排查","url":"65.html","id":"65","date":"2018-08-09T04:58:33.000Z","_content":"\n背景\n--\n\n- [XXL-Job](https://github.com/xuxueli/xxl-job) 是一套开源的任务调度框架，目前服务端部署了一套 XXL-Job 服务，用于监控线上服务质量\n- 由于 Ucloud 出现过几次内网域名服务器故障，我们在 XXL-Job 中增加了定时任务监控第三方域名连通状态，并报警到钉钉群\n\n问题描述\n----\n\n- 添加三方域名报警之后，钉钉群中经常收到报警，但是实际观察时，发现服务并无问题，报警为误报\n\n排查过程\n----\n\n- 查看报警对应的执行脚本，核心代码如下\n\n    ``` bash\n    ping -c 5 target.com\n    if (($? == 0))\n    then\n        //正常\n    else\n        //报警\n        exit 1;\n    fi\n    ```\n\n- 查看报警对应的脚本执行日志，发现如下报错\n\n    ``` bash\n    ping: unknown host\n    ```\n\n- 初步判断是域名解析有问题导致报警，使用 `dig` 和 `nslookup` 查看域名解析情况，结果正常返回。由于报警也是偶发，觉得可能是域名解析偶发失败导致 `ping` 命令报错\n\n    ``` bash\n    [work@monitor01 ~]$ nslookup target.com\n    Server:       10.9.255.1\n    Address:  10.9.255.1#53\n\n    Non-authoritative answer:\n    Name: target.com\n    Address: xx.xx.xx.xx\n    ```\n\n- 在 XXL-Job 部署的机器上尝试复现问题，脚本如下。执行脚本，直到有报警时停止，查看日志，没有失败的情况\n\n    ``` bash\n    while true\n    do\n      echo \"`date`============\"\n      ping -c1 target.com\n      echo \"result: $?\"\n    done\n    ```\n\n- 在 XXL-Job 机器上观察 XXL-Job 进程，使用 `ps -elf` 命令追踪父进程。发现进程是运行在 Docker 容器中的\n\n    ``` bash\n    [work@monitor01 ~]$ ps -elf | grep 31525\n    0 S root     31525  1689  0  80      0 - 86935 futex_ Jun29 ?           00:16:10    /usr/bin/docker-containerd-shim    current    6b0f5c6aa2f52318867466a32774071    f7bbf540779ef92bb16ccf00494c6c5    /var/run/docker/libcontainerd/6    0f5c6aa2f52318867466a327740711f    bbf540779ef92bb16ccf00494c6c5e    /usr/libexec/docker/docker-runc-current\n    ```\n\n- 容器和宿主机的网络环境是隔离的，所以 XXL-Job 报警时，宿主机上的脚本没有复现问题。于是在容器中继续执行脚本，尝试复现问题\n- 脚本执行几分钟后，在日志中观察到有报错的情况。这里注意到，报错的地方似乎花费的时间比较久\n\n    ``` bash\n    Mon Jul  2 08:30:35 UTC     2018============\n    ping: unknown host\n    result: 1\n    Mon Jul  2 08:30:37 UTC     2018============\n    ```\n\n- 对脚本进行调整，记录调用时间\n\n    ``` bash\n    time ping -c1 target.com\n    ```\n\n- 重新执行脚本，发现报错时，`ping` 命令的调用花费了一秒左右的时间。感觉可能是 DNS 解析超时了。\n\n    ``` bash\n    Mon Jul  2 09:43:12 UTC     2018============\n    ping: unknown host\n\n    real    0m1.049s\n    user    0m0.002s\n    sys     0m0.002s\n    result: 1\n    ```\n\n- 查看容器 DNS 解析配置\n\n    ``` bash\n    root@f9c78250c2a0:~# cat        /etc/resolv.conf\n    search xxx.com\n    nameserver 127.0.0.11\n    options timeout:1 attempts:1        rotate single-request-reopen        ndots:0\n    ```\n\n- 通过 `man resolv.conf` 查阅 `resolv.conf` 参数的含义。发现容器内的 DNS 解析超时时间配置成了一秒，并且只尝试一次。DNS 使用 UDP 协议传输数据。UDP 协议设计上就是不可靠的，所以会存在丢包的情况，而且 DNS 解析需要去公网域名服务器请求数据，延迟也有不确定性。当 DNS 解析失败时，`ping` 命令就会报错，进而触发报警。\n\n    ``` properties\n    timeout:n\n      Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server.  Measured in seconds, the  default is RES_TIMEOUT (currently 5, see <resolv.h>).  The value for this option is silently capped to 30.\n\n    attempts:n\n      Sets  the  number  of  times  the resolver will send a query to its name servers before giving up and returning an error to the calling application.  The default is RES_DFLRETRY (currently 2, see <resolv.h>).  The value for this option is silently capped to 5.\n    ```\n\n- 问题到这里基本定位完成，开始尝试解决问题。查阅 Docker 官方文档中关于[网络的配置](https://docs.docker.com/config/containers/container-networking/#dns-services)，发现可以通过 `dns_opt` 参数配置容器的 DNS 解析配置\n\n    ``` bash\n    --dns-opt A key-value pair representing a DNS option and its value. See your operating system’s documentation for resolv.conf for valid options.\n    ```\n\n- 修改容器配置，将 DNS 解析超时设置为 2s，重试一次。重启服务，观察半个小时，不再出现误报，问题解决\n\n    ``` yaml\n    dns_opt:\n      - timeout:2\n      - attempts:2\n      - single-request\n      - rotate\n    ```\n\n一句话总结\n-----\n\n容器和宿主机 DNS 解析配置不同，导致容器内 ping 命令调用偶发失败，引发报警误报。通过 `dns_opt` 参数修改容器 DNS 超时时间和重试次数后，问题解决。","source":"_posts/dns_config_problem.md","raw":"---\ntitle: DNS 配置有误导致监控误报的问题排查\ntags:\n  - DNS\n  - Docker\n  - Problem\nurl: 65.html\nid: 65\ncategories:\n  - Tech\ndate: 2018-08-09 12:58:33\n---\n\n背景\n--\n\n- [XXL-Job](https://github.com/xuxueli/xxl-job) 是一套开源的任务调度框架，目前服务端部署了一套 XXL-Job 服务，用于监控线上服务质量\n- 由于 Ucloud 出现过几次内网域名服务器故障，我们在 XXL-Job 中增加了定时任务监控第三方域名连通状态，并报警到钉钉群\n\n问题描述\n----\n\n- 添加三方域名报警之后，钉钉群中经常收到报警，但是实际观察时，发现服务并无问题，报警为误报\n\n排查过程\n----\n\n- 查看报警对应的执行脚本，核心代码如下\n\n    ``` bash\n    ping -c 5 target.com\n    if (($? == 0))\n    then\n        //正常\n    else\n        //报警\n        exit 1;\n    fi\n    ```\n\n- 查看报警对应的脚本执行日志，发现如下报错\n\n    ``` bash\n    ping: unknown host\n    ```\n\n- 初步判断是域名解析有问题导致报警，使用 `dig` 和 `nslookup` 查看域名解析情况，结果正常返回。由于报警也是偶发，觉得可能是域名解析偶发失败导致 `ping` 命令报错\n\n    ``` bash\n    [work@monitor01 ~]$ nslookup target.com\n    Server:       10.9.255.1\n    Address:  10.9.255.1#53\n\n    Non-authoritative answer:\n    Name: target.com\n    Address: xx.xx.xx.xx\n    ```\n\n- 在 XXL-Job 部署的机器上尝试复现问题，脚本如下。执行脚本，直到有报警时停止，查看日志，没有失败的情况\n\n    ``` bash\n    while true\n    do\n      echo \"`date`============\"\n      ping -c1 target.com\n      echo \"result: $?\"\n    done\n    ```\n\n- 在 XXL-Job 机器上观察 XXL-Job 进程，使用 `ps -elf` 命令追踪父进程。发现进程是运行在 Docker 容器中的\n\n    ``` bash\n    [work@monitor01 ~]$ ps -elf | grep 31525\n    0 S root     31525  1689  0  80      0 - 86935 futex_ Jun29 ?           00:16:10    /usr/bin/docker-containerd-shim    current    6b0f5c6aa2f52318867466a32774071    f7bbf540779ef92bb16ccf00494c6c5    /var/run/docker/libcontainerd/6    0f5c6aa2f52318867466a327740711f    bbf540779ef92bb16ccf00494c6c5e    /usr/libexec/docker/docker-runc-current\n    ```\n\n- 容器和宿主机的网络环境是隔离的，所以 XXL-Job 报警时，宿主机上的脚本没有复现问题。于是在容器中继续执行脚本，尝试复现问题\n- 脚本执行几分钟后，在日志中观察到有报错的情况。这里注意到，报错的地方似乎花费的时间比较久\n\n    ``` bash\n    Mon Jul  2 08:30:35 UTC     2018============\n    ping: unknown host\n    result: 1\n    Mon Jul  2 08:30:37 UTC     2018============\n    ```\n\n- 对脚本进行调整，记录调用时间\n\n    ``` bash\n    time ping -c1 target.com\n    ```\n\n- 重新执行脚本，发现报错时，`ping` 命令的调用花费了一秒左右的时间。感觉可能是 DNS 解析超时了。\n\n    ``` bash\n    Mon Jul  2 09:43:12 UTC     2018============\n    ping: unknown host\n\n    real    0m1.049s\n    user    0m0.002s\n    sys     0m0.002s\n    result: 1\n    ```\n\n- 查看容器 DNS 解析配置\n\n    ``` bash\n    root@f9c78250c2a0:~# cat        /etc/resolv.conf\n    search xxx.com\n    nameserver 127.0.0.11\n    options timeout:1 attempts:1        rotate single-request-reopen        ndots:0\n    ```\n\n- 通过 `man resolv.conf` 查阅 `resolv.conf` 参数的含义。发现容器内的 DNS 解析超时时间配置成了一秒，并且只尝试一次。DNS 使用 UDP 协议传输数据。UDP 协议设计上就是不可靠的，所以会存在丢包的情况，而且 DNS 解析需要去公网域名服务器请求数据，延迟也有不确定性。当 DNS 解析失败时，`ping` 命令就会报错，进而触发报警。\n\n    ``` properties\n    timeout:n\n      Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server.  Measured in seconds, the  default is RES_TIMEOUT (currently 5, see <resolv.h>).  The value for this option is silently capped to 30.\n\n    attempts:n\n      Sets  the  number  of  times  the resolver will send a query to its name servers before giving up and returning an error to the calling application.  The default is RES_DFLRETRY (currently 2, see <resolv.h>).  The value for this option is silently capped to 5.\n    ```\n\n- 问题到这里基本定位完成，开始尝试解决问题。查阅 Docker 官方文档中关于[网络的配置](https://docs.docker.com/config/containers/container-networking/#dns-services)，发现可以通过 `dns_opt` 参数配置容器的 DNS 解析配置\n\n    ``` bash\n    --dns-opt A key-value pair representing a DNS option and its value. See your operating system’s documentation for resolv.conf for valid options.\n    ```\n\n- 修改容器配置，将 DNS 解析超时设置为 2s，重试一次。重启服务，观察半个小时，不再出现误报，问题解决\n\n    ``` yaml\n    dns_opt:\n      - timeout:2\n      - attempts:2\n      - single-request\n      - rotate\n    ```\n\n一句话总结\n-----\n\n容器和宿主机 DNS 解析配置不同，导致容器内 ping 命令调用偶发失败，引发报警误报。通过 `dns_opt` 参数修改容器 DNS 超时时间和重试次数后，问题解决。","slug":"dns_config_problem","published":1,"updated":"2019-01-08T16:57:49.290Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqo1fwqj00002kfyt5wjvjrw","content":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><ul>\n<li><a href=\"https://github.com/xuxueli/xxl-job\" target=\"_blank\" rel=\"noopener\">XXL-Job</a> 是一套开源的任务调度框架，目前服务端部署了一套 XXL-Job 服务，用于监控线上服务质量</li>\n<li>由于 Ucloud 出现过几次内网域名服务器故障，我们在 XXL-Job 中增加了定时任务监控第三方域名连通状态，并报警到钉钉群</li>\n</ul>\n<h2 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h2><ul>\n<li>添加三方域名报警之后，钉钉群中经常收到报警，但是实际观察时，发现服务并无问题，报警为误报</li>\n</ul>\n<h2 id=\"排查过程\"><a href=\"#排查过程\" class=\"headerlink\" title=\"排查过程\"></a>排查过程</h2><ul>\n<li><p>查看报警对应的执行脚本，核心代码如下</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  <span class=\"token function\">ping</span> -c 5 target.com\n  <span class=\"token keyword\">if</span> <span class=\"token variable\"><span class=\"token punctuation\">((</span>$<span class=\"token operator\">?</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">))</span></span>\n  <span class=\"token keyword\">then</span>\n      //正常\n  <span class=\"token keyword\">else</span>\n      //报警\n      <span class=\"token keyword\">exit</span> 1<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">fi</span>\n</code></pre>\n</li>\n<li><p>查看报警对应的脚本执行日志，发现如下报错</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  ping: unknown host\n</code></pre>\n</li>\n<li><p>初步判断是域名解析有问题导致报警，使用 <code>dig</code> 和 <code>nslookup</code> 查看域名解析情况，结果正常返回。由于报警也是偶发，觉得可能是域名解析偶发失败导致 <code>ping</code> 命令报错</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  <span class=\"token punctuation\">[</span>work@monitor01 ~<span class=\"token punctuation\">]</span>$ <span class=\"token function\">nslookup</span> target.com\n  Server:       10.9.255.1\n  Address:  10.9.255.1<span class=\"token comment\" spellcheck=\"true\">#53</span>\n\n  Non-authoritative answer:\n  Name: target.com\n  Address: xx.xx.xx.xx\n</code></pre>\n</li>\n<li><p>在 XXL-Job 部署的机器上尝试复现问题，脚本如下。执行脚本，直到有报警时停止，查看日志，没有失败的情况</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  <span class=\"token keyword\">while</span> <span class=\"token boolean\">true</span>\n  <span class=\"token keyword\">do</span>\n    <span class=\"token keyword\">echo</span> <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token function\">date</span><span class=\"token variable\">`</span></span>============\"</span>\n    <span class=\"token function\">ping</span> -c1 target.com\n    <span class=\"token keyword\">echo</span> <span class=\"token string\">\"result: <span class=\"token variable\">$?</span>\"</span>\n  <span class=\"token keyword\">done</span>\n</code></pre>\n</li>\n<li><p>在 XXL-Job 机器上观察 XXL-Job 进程，使用 <code>ps -elf</code> 命令追踪父进程。发现进程是运行在 Docker 容器中的</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  <span class=\"token punctuation\">[</span>work@monitor01 ~<span class=\"token punctuation\">]</span>$ <span class=\"token function\">ps</span> -elf <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> 31525\n  0 S root     31525  1689  0  80      0 - 86935 futex_ Jun29 ?           00:16:10    /usr/bin/docker-containerd-shim    current    6b0f5c6aa2f52318867466a32774071    f7bbf540779ef92bb16ccf00494c6c5    /var/run/docker/libcontainerd/6    0f5c6aa2f52318867466a327740711f    bbf540779ef92bb16ccf00494c6c5e    /usr/libexec/docker/docker-runc-current\n</code></pre>\n</li>\n<li><p>容器和宿主机的网络环境是隔离的，所以 XXL-Job 报警时，宿主机上的脚本没有复现问题。于是在容器中继续执行脚本，尝试复现问题</p>\n</li>\n<li><p>脚本执行几分钟后，在日志中观察到有报错的情况。这里注意到，报错的地方似乎花费的时间比较久</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  Mon Jul  2 08:30:35 UTC     2018<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span>\n  ping: unknown host\n  result: 1\n  Mon Jul  2 08:30:37 UTC     2018<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span>\n</code></pre>\n</li>\n<li><p>对脚本进行调整，记录调用时间</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  <span class=\"token function\">time</span> <span class=\"token function\">ping</span> -c1 target.com\n</code></pre>\n</li>\n<li><p>重新执行脚本，发现报错时，<code>ping</code> 命令的调用花费了一秒左右的时间。感觉可能是 DNS 解析超时了。</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  Mon Jul  2 09:43:12 UTC     2018<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span>\n  ping: unknown host\n\n  real    0m1.049s\n  user    0m0.002s\n  sys     0m0.002s\n  result: 1\n</code></pre>\n</li>\n<li><p>查看容器 DNS 解析配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  root@f9c78250c2a0:~<span class=\"token comment\" spellcheck=\"true\"># cat        /etc/resolv.conf</span>\n  search xxx.com\n  nameserver 127.0.0.11\n  options timeout:1 attempts:1        rotate single-request-reopen        ndots:0\n</code></pre>\n</li>\n<li><p>通过 <code>man resolv.conf</code> 查阅 <code>resolv.conf</code> 参数的含义。发现容器内的 DNS 解析超时时间配置成了一秒，并且只尝试一次。DNS 使用 UDP 协议传输数据。UDP 协议设计上就是不可靠的，所以会存在丢包的情况，而且 DNS 解析需要去公网域名服务器请求数据，延迟也有不确定性。当 DNS 解析失败时，<code>ping</code> 命令就会报错，进而触发报警。</p>\n<pre class=\" language-properties\"><code class=\"language-properties\"><span class=\"token attr-name\">  timeout</span><span class=\"token punctuation\">:</span><span class=\"token attr-value\">n</span>\n<span class=\"token attr-name\">    Sets</span> <span class=\"token attr-value\">the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server.  Measured in seconds, the  default is RES_TIMEOUT (currently 5, see &lt;resolv.h>).  The value for this option is silently capped to 30.</span>\n\n<span class=\"token attr-name\">  attempts</span><span class=\"token punctuation\">:</span><span class=\"token attr-value\">n</span>\n<span class=\"token attr-name\">    Sets</span> <span class=\"token attr-value\"> the  number  of  times  the resolver will send a query to its name servers before giving up and returning an error to the calling application.  The default is RES_DFLRETRY (currently 2, see &lt;resolv.h>).  The value for this option is silently capped to 5.</span>\n</code></pre>\n</li>\n<li><p>问题到这里基本定位完成，开始尝试解决问题。查阅 Docker 官方文档中关于<a href=\"https://docs.docker.com/config/containers/container-networking/#dns-services\" target=\"_blank\" rel=\"noopener\">网络的配置</a>，发现可以通过 <code>dns_opt</code> 参数配置容器的 DNS 解析配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  --dns-opt A key-value pair representing a DNS option and its value. See your operating system’s documentation <span class=\"token keyword\">for</span> resolv.conf <span class=\"token keyword\">for</span> valid options.\n</code></pre>\n</li>\n<li><p>修改容器配置，将 DNS 解析超时设置为 2s，重试一次。重启服务，观察半个小时，不再出现误报，问题解决</p>\n<pre class=\" language-yaml\"><code class=\"language-yaml\">  <span class=\"token key atrule\">dns_opt</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> timeout<span class=\"token punctuation\">:</span><span class=\"token number\">2</span>\n    <span class=\"token punctuation\">-</span> attempts<span class=\"token punctuation\">:</span><span class=\"token number\">2</span>\n    <span class=\"token punctuation\">-</span> single<span class=\"token punctuation\">-</span>request\n    <span class=\"token punctuation\">-</span> rotate\n</code></pre>\n</li>\n</ul>\n<h2 id=\"一句话总结\"><a href=\"#一句话总结\" class=\"headerlink\" title=\"一句话总结\"></a>一句话总结</h2><p>容器和宿主机 DNS 解析配置不同，导致容器内 ping 命令调用偶发失败，引发报警误报。通过 <code>dns_opt</code> 参数修改容器 DNS 超时时间和重试次数后，问题解决。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><ul>\n<li><a href=\"https://github.com/xuxueli/xxl-job\" target=\"_blank\" rel=\"noopener\">XXL-Job</a> 是一套开源的任务调度框架，目前服务端部署了一套 XXL-Job 服务，用于监控线上服务质量</li>\n<li>由于 Ucloud 出现过几次内网域名服务器故障，我们在 XXL-Job 中增加了定时任务监控第三方域名连通状态，并报警到钉钉群</li>\n</ul>\n<h2 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h2><ul>\n<li>添加三方域名报警之后，钉钉群中经常收到报警，但是实际观察时，发现服务并无问题，报警为误报</li>\n</ul>\n<h2 id=\"排查过程\"><a href=\"#排查过程\" class=\"headerlink\" title=\"排查过程\"></a>排查过程</h2><ul>\n<li><p>查看报警对应的执行脚本，核心代码如下</p>\n<pre><code class=\"bash\">  ping -c 5 target.com\n  if (($? == 0))\n  then\n      //正常\n  else\n      //报警\n      exit 1;\n  fi\n</code></pre>\n</li>\n<li><p>查看报警对应的脚本执行日志，发现如下报错</p>\n<pre><code class=\"bash\">  ping: unknown host\n</code></pre>\n</li>\n<li><p>初步判断是域名解析有问题导致报警，使用 <code>dig</code> 和 <code>nslookup</code> 查看域名解析情况，结果正常返回。由于报警也是偶发，觉得可能是域名解析偶发失败导致 <code>ping</code> 命令报错</p>\n<pre><code class=\"bash\">  [work@monitor01 ~]$ nslookup target.com\n  Server:       10.9.255.1\n  Address:  10.9.255.1#53\n\n  Non-authoritative answer:\n  Name: target.com\n  Address: xx.xx.xx.xx\n</code></pre>\n</li>\n<li><p>在 XXL-Job 部署的机器上尝试复现问题，脚本如下。执行脚本，直到有报警时停止，查看日志，没有失败的情况</p>\n<pre><code class=\"bash\">  while true\n  do\n    echo &quot;`date`============&quot;\n    ping -c1 target.com\n    echo &quot;result: $?&quot;\n  done\n</code></pre>\n</li>\n<li><p>在 XXL-Job 机器上观察 XXL-Job 进程，使用 <code>ps -elf</code> 命令追踪父进程。发现进程是运行在 Docker 容器中的</p>\n<pre><code class=\"bash\">  [work@monitor01 ~]$ ps -elf | grep 31525\n  0 S root     31525  1689  0  80      0 - 86935 futex_ Jun29 ?           00:16:10    /usr/bin/docker-containerd-shim    current    6b0f5c6aa2f52318867466a32774071    f7bbf540779ef92bb16ccf00494c6c5    /var/run/docker/libcontainerd/6    0f5c6aa2f52318867466a327740711f    bbf540779ef92bb16ccf00494c6c5e    /usr/libexec/docker/docker-runc-current\n</code></pre>\n</li>\n<li><p>容器和宿主机的网络环境是隔离的，所以 XXL-Job 报警时，宿主机上的脚本没有复现问题。于是在容器中继续执行脚本，尝试复现问题</p>\n</li>\n<li><p>脚本执行几分钟后，在日志中观察到有报错的情况。这里注意到，报错的地方似乎花费的时间比较久</p>\n<pre><code class=\"bash\">  Mon Jul  2 08:30:35 UTC     2018============\n  ping: unknown host\n  result: 1\n  Mon Jul  2 08:30:37 UTC     2018============\n</code></pre>\n</li>\n<li><p>对脚本进行调整，记录调用时间</p>\n<pre><code class=\"bash\">  time ping -c1 target.com\n</code></pre>\n</li>\n<li><p>重新执行脚本，发现报错时，<code>ping</code> 命令的调用花费了一秒左右的时间。感觉可能是 DNS 解析超时了。</p>\n<pre><code class=\"bash\">  Mon Jul  2 09:43:12 UTC     2018============\n  ping: unknown host\n\n  real    0m1.049s\n  user    0m0.002s\n  sys     0m0.002s\n  result: 1\n</code></pre>\n</li>\n<li><p>查看容器 DNS 解析配置</p>\n<pre><code class=\"bash\">  root@f9c78250c2a0:~# cat        /etc/resolv.conf\n  search xxx.com\n  nameserver 127.0.0.11\n  options timeout:1 attempts:1        rotate single-request-reopen        ndots:0\n</code></pre>\n</li>\n<li><p>通过 <code>man resolv.conf</code> 查阅 <code>resolv.conf</code> 参数的含义。发现容器内的 DNS 解析超时时间配置成了一秒，并且只尝试一次。DNS 使用 UDP 协议传输数据。UDP 协议设计上就是不可靠的，所以会存在丢包的情况，而且 DNS 解析需要去公网域名服务器请求数据，延迟也有不确定性。当 DNS 解析失败时，<code>ping</code> 命令就会报错，进而触发报警。</p>\n<pre><code class=\"properties\">  timeout:n\n    Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server.  Measured in seconds, the  default is RES_TIMEOUT (currently 5, see &lt;resolv.h&gt;).  The value for this option is silently capped to 30.\n\n  attempts:n\n    Sets  the  number  of  times  the resolver will send a query to its name servers before giving up and returning an error to the calling application.  The default is RES_DFLRETRY (currently 2, see &lt;resolv.h&gt;).  The value for this option is silently capped to 5.\n</code></pre>\n</li>\n<li><p>问题到这里基本定位完成，开始尝试解决问题。查阅 Docker 官方文档中关于<a href=\"https://docs.docker.com/config/containers/container-networking/#dns-services\" target=\"_blank\" rel=\"noopener\">网络的配置</a>，发现可以通过 <code>dns_opt</code> 参数配置容器的 DNS 解析配置</p>\n<pre><code class=\"bash\">  --dns-opt A key-value pair representing a DNS option and its value. See your operating system’s documentation for resolv.conf for valid options.\n</code></pre>\n</li>\n<li><p>修改容器配置，将 DNS 解析超时设置为 2s，重试一次。重启服务，观察半个小时，不再出现误报，问题解决</p>\n<pre><code class=\"yaml\">  dns_opt:\n    - timeout:2\n    - attempts:2\n    - single-request\n    - rotate\n</code></pre>\n</li>\n</ul>\n<h2 id=\"一句话总结\"><a href=\"#一句话总结\" class=\"headerlink\" title=\"一句话总结\"></a>一句话总结</h2><p>容器和宿主机 DNS 解析配置不同，导致容器内 ping 命令调用偶发失败，引发报警误报。通过 <code>dns_opt</code> 参数修改容器 DNS 超时时间和重试次数后，问题解决。</p>\n"},{"title":"小试 Docker swarm mode","url":"59.html","id":"59","date":"2016-12-14T10:12:37.000Z","_content":"\n最近在公司尝试将测试环境 docker 化，由于组件比较多，考虑引入容器编排方案。首先尝试使用 docker-compose 来管理各个组件实例。可以跑通基本逻辑，但是目前没有服务发现框架，只能使用 docker 内置网络中的 DNS 发现其它服务，这限定了测试环境只能跑在单机环境上，时间久了各种 OOM。最近看到 docker 新版本附带的 swarm mode，尝试搭建了一套多机 docker 环境，感觉很满足当前的需求，并且对代码基本零侵入。简单的记录了一下搭建过程以及一些注意事项。\n\n## Swarm mode 简介\n\n### 背景\n\n- docker swarm 是 docker 官方编排项目之一，提供将多个 docker engine 实例变成一台虚拟 docker engine 实例的能力，便于 docker 容器集群管理\n- docker 1.12 版本推出了 swarm mode 功能，将 docker swarm 深度集成到 docker engine 中，提供了整套更为简洁的 api 对 swarm 集群进行管理。相对于原生的 docker swarm，swarm mode 部署更为简单，无需外置的服务发现框架，并且提供了容器路由服务\n\n### 概念\n\n- Node: node 是 swarm 集群中一个 docker engine 实例\n  - Manager node: 对整体集群进行管理和编排，并维护整个集群\n  - Worker node: 接收 manager node 分配的 tasks，并运行，默认情况下，manager node 本身也作为一个 worker node 运行 task，可以通过改变配置让 manager node 变成一个 manager-only 的纯管理节点\n- Task: swarm 集群任务的基本单元，通常是一个 docker container 的实例\n- Service: 由一组同类型 task 聚合而成，是 swarm 集群中主要操作对象\n- Load balancing: swarm 集群有一套内置的负载均衡策略提供外部访问到目标容器的路由，在创建 Service 时可以发布端口到外部网络上，访问 swarm 集群任意节点该端口的请求都会被路由到该 Service\n\n## Swarm mode quick start\n\n### 初始化 swarm 集群\n\n1. 初始化机器，安装 docker-engine （版本需要高于 1.12）\n2. 选择一台机器作为 swarm manager 节点，在 console 中运行 `docker swarm init` 创建 swarm 集群，命令会返回加入集群的命令\n\n    ``` bash\n    Swarm initialized: current node (c8dzd8xek2c9csoxj27ycl1nh) is now a manager.\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join \\\n        --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n        192.168.65.2:2377\n\n    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the     instructions.\n    ```\n\n3. 在另一台机器上，运行提示中的命令加入集群，如果没有保存之前的提示，可以通过 `docker swarm join-token worker` 查询\n\n    ``` bash\n    docker swarm join \\\n        --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n        192.168.65.2:2377\n    ```\n\n4. 在 manager 节点上运行 `docker info` 可以看到 swarm 集群的信息\n\n    ``` bash\n    Swarm: active\n     NodeID: c8dzd8xek2c9csoxj27ycl1nh\n     Is Manager: true\n     ClusterID: cj75fozp5effsiyuuq2dixv95\n     Managers: 1\n     Nodes: 2\n     Orchestration:\n      Task History Retention Limit: 5\n     Raft:\n      Snapshot Interval: 10000\n      Heartbeat Tick: 1\n      Election Tick: 3\n     Dispatcher:\n      Heartbeat Period: 5 seconds\n     CA Configuration:\n      Expiry Duration: 3 months\n     Node Address: 192.168.65.2\n    ```\n\n5. 在节点上运行 `docker swarm leave` 可以让当前节点离开集群，如果是管理节点，需要增加 `--force` 参数\n\n### 创建一个 service\n\n1. 在 manager 节点上运行命令 `docker service create --replicas 1 --name redis docker-registry-cn.easemob.com/redis`创建 redis 服务, `replicas` 参数指定该服务中的 task 数量\n    - 如果是私有 registry，需要在 manager 节点上执行 `docker login`，然后创建服务时，增加 `--with-registry-auth` 参数将认证信息发送到 worker 节点\n2. 在 manager 节点上运行 `docker service ls` 查看所有服务状态\n\n    ``` bash\n    ID            NAME   REPLICAS      IMAGE                                     COMMAND\n    0nqfp11n2xgb  redis  1/1           docker-registry-cn.easemob.    com/redis\n    ```\n\n3. 在 manager 节点上运行 `docker service ps redis` 查看 redis 服务状态\n\n    ``` bash\n    ID                         NAME     IMAGE                                 NODE  DESIRED STATE  CURRENT STATE         ERROR\n    3qpkmxptn8o336h161183a0vz  redis.1  docker-registry-cn.easemob.com/redis  moby  Running        Running 17 hours ago\n    ```\n\n4. 在 manager 节点上运行 `docker service update redis` 更新服务。例如可以用 `docker service update redis --publish-add 6379:6379` 发布 redis 服务到 swarm 集群 6379 端口上（也可以在创建服务时使用 --publish 参数发布），在 swarm 任意节点上运行 `redis-cli` 都可以连接到 redis 服务\n5. 在 manager 节点上运行 `docker service rm redis` 可以删除服务\n\n### Service 间网络调用\n\n- 如果 service publish 了端口，可以通过任意 swarm 节点 publish 端口进行调用\n\n    ``` bash\n    ➜  ~ docker service update --publish-add 6379:6379 redis1\n    redis1\n    ➜  ~ telnet localhost 6379\n    Trying ::1...\n    Connected to localhost.\n    Escape character is '^]'.\n    set test aaa\n    +OK\n    ```\n\n- 创建一个 overlay 的网络，创建服务时，通过 `--network` 参数连接到 overlay 网络上。通过内建的 DNS 服务，可以通过 service name 解析出 task IP\n\n    ``` bash\n    ➜  ~ docker network create --driver overlay --subnet 10.0.10.0/24 sandbox\n    e7q4c68ybbw7xhrkb0at47k00\n    ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis1  docker-registry-cn.easemob.com/redis\n    0dfqszxp925id4ma9blolyjmz\n    ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis2  docker-registry-cn.easemob.com/redis\n    c3khd0snpu13ixx8popuoludx\n    ➜  ~ docker ps\n    CONTAINER ID        IMAGE                                         COMMAND                  CREATED             STATUS              PORTS               NAMES\n    4c92e01d25fd        docker-registry-cn.easemob.com/redis:latest   \"/entrypoint.sh redis\"   12 seconds ago      Up 9 seconds        6379/tcp            redis2.1.4qbw5c0hawat5rr50hgzpxj7l\n    c60b4659e768        docker-registry-cn.easemob.com/redis:latest   \"/entrypoint.sh redis\"   6 minutes ago       Up 6 minutes        6379/tcp            redis1.1.4pvn93a6i2n5teou41mddmlxr\n    ➜  ~ docker exec -it c60b4659e768 /bin/bash\n    root@c60b4659e768:/data# ping redis2\n    PING redis2 (10.0.10.4): 56 data bytes\n    64 bytes from 10.0.10.4: icmp_seq=0 ttl=64 time=0.109 ms\n    ```\n\n### 一些坑点\n\n- 截止 docker 最新版本（1.12.3），在 overlay 网络中，以 VIP 方式启动的服务，可以解析 DNS，但是无法 `ping` IP，某些依赖 `ping` 检查网络连通的程序会有问题，见 [https://github.com/docker/docker/issues/25497](https://github.com/docker/docker/issues/25497)。解决方案是启动模式换成 dnsrr （创建服务时增加参数 --endpoint-mode dnsrr），或者使用 tasks.${service_name} 的方式调用\n- 在某些操作系统（例如 Suse）上，service publish 的端口无法连接，原因不明，可能和缺少某些内核模块有关。建议使用 Centos7\n- swarm manager 会在 service 中 task 退出时重新提交 task，某些需要一次性运行的 docker image （例如环境初始化脚本的执行）endpoint 或者 cmd 需要修改成 block 形式，以免退出后被重复提交。Docker 1.13 版本允许 `docker run` 启动的容器 attach 到 swarm service 使用的 network 上，可以将一次性运行的 image 直接以 `docker run` 的方式启动\n- `docker service update --image myimage:latest` 不会拉取新镜像，即使远端有更新的版本，只能通过手动拉取镜像后重启 service 来更新服务。这个 bug 会在 docker 1.13 上被修复\n\nHave fun :)","source":"_posts/docker-swarm-mode.md","raw":"---\ntitle: 小试 Docker swarm mode\ntags:\n  - Docker\n  - Swarm\nurl: 59.html\nid: 59\ncategories:\n  - Tech\ndate: 2016-12-14 18:12:37\n---\n\n最近在公司尝试将测试环境 docker 化，由于组件比较多，考虑引入容器编排方案。首先尝试使用 docker-compose 来管理各个组件实例。可以跑通基本逻辑，但是目前没有服务发现框架，只能使用 docker 内置网络中的 DNS 发现其它服务，这限定了测试环境只能跑在单机环境上，时间久了各种 OOM。最近看到 docker 新版本附带的 swarm mode，尝试搭建了一套多机 docker 环境，感觉很满足当前的需求，并且对代码基本零侵入。简单的记录了一下搭建过程以及一些注意事项。\n\n## Swarm mode 简介\n\n### 背景\n\n- docker swarm 是 docker 官方编排项目之一，提供将多个 docker engine 实例变成一台虚拟 docker engine 实例的能力，便于 docker 容器集群管理\n- docker 1.12 版本推出了 swarm mode 功能，将 docker swarm 深度集成到 docker engine 中，提供了整套更为简洁的 api 对 swarm 集群进行管理。相对于原生的 docker swarm，swarm mode 部署更为简单，无需外置的服务发现框架，并且提供了容器路由服务\n\n### 概念\n\n- Node: node 是 swarm 集群中一个 docker engine 实例\n  - Manager node: 对整体集群进行管理和编排，并维护整个集群\n  - Worker node: 接收 manager node 分配的 tasks，并运行，默认情况下，manager node 本身也作为一个 worker node 运行 task，可以通过改变配置让 manager node 变成一个 manager-only 的纯管理节点\n- Task: swarm 集群任务的基本单元，通常是一个 docker container 的实例\n- Service: 由一组同类型 task 聚合而成，是 swarm 集群中主要操作对象\n- Load balancing: swarm 集群有一套内置的负载均衡策略提供外部访问到目标容器的路由，在创建 Service 时可以发布端口到外部网络上，访问 swarm 集群任意节点该端口的请求都会被路由到该 Service\n\n## Swarm mode quick start\n\n### 初始化 swarm 集群\n\n1. 初始化机器，安装 docker-engine （版本需要高于 1.12）\n2. 选择一台机器作为 swarm manager 节点，在 console 中运行 `docker swarm init` 创建 swarm 集群，命令会返回加入集群的命令\n\n    ``` bash\n    Swarm initialized: current node (c8dzd8xek2c9csoxj27ycl1nh) is now a manager.\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join \\\n        --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n        192.168.65.2:2377\n\n    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the     instructions.\n    ```\n\n3. 在另一台机器上，运行提示中的命令加入集群，如果没有保存之前的提示，可以通过 `docker swarm join-token worker` 查询\n\n    ``` bash\n    docker swarm join \\\n        --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n        192.168.65.2:2377\n    ```\n\n4. 在 manager 节点上运行 `docker info` 可以看到 swarm 集群的信息\n\n    ``` bash\n    Swarm: active\n     NodeID: c8dzd8xek2c9csoxj27ycl1nh\n     Is Manager: true\n     ClusterID: cj75fozp5effsiyuuq2dixv95\n     Managers: 1\n     Nodes: 2\n     Orchestration:\n      Task History Retention Limit: 5\n     Raft:\n      Snapshot Interval: 10000\n      Heartbeat Tick: 1\n      Election Tick: 3\n     Dispatcher:\n      Heartbeat Period: 5 seconds\n     CA Configuration:\n      Expiry Duration: 3 months\n     Node Address: 192.168.65.2\n    ```\n\n5. 在节点上运行 `docker swarm leave` 可以让当前节点离开集群，如果是管理节点，需要增加 `--force` 参数\n\n### 创建一个 service\n\n1. 在 manager 节点上运行命令 `docker service create --replicas 1 --name redis docker-registry-cn.easemob.com/redis`创建 redis 服务, `replicas` 参数指定该服务中的 task 数量\n    - 如果是私有 registry，需要在 manager 节点上执行 `docker login`，然后创建服务时，增加 `--with-registry-auth` 参数将认证信息发送到 worker 节点\n2. 在 manager 节点上运行 `docker service ls` 查看所有服务状态\n\n    ``` bash\n    ID            NAME   REPLICAS      IMAGE                                     COMMAND\n    0nqfp11n2xgb  redis  1/1           docker-registry-cn.easemob.    com/redis\n    ```\n\n3. 在 manager 节点上运行 `docker service ps redis` 查看 redis 服务状态\n\n    ``` bash\n    ID                         NAME     IMAGE                                 NODE  DESIRED STATE  CURRENT STATE         ERROR\n    3qpkmxptn8o336h161183a0vz  redis.1  docker-registry-cn.easemob.com/redis  moby  Running        Running 17 hours ago\n    ```\n\n4. 在 manager 节点上运行 `docker service update redis` 更新服务。例如可以用 `docker service update redis --publish-add 6379:6379` 发布 redis 服务到 swarm 集群 6379 端口上（也可以在创建服务时使用 --publish 参数发布），在 swarm 任意节点上运行 `redis-cli` 都可以连接到 redis 服务\n5. 在 manager 节点上运行 `docker service rm redis` 可以删除服务\n\n### Service 间网络调用\n\n- 如果 service publish 了端口，可以通过任意 swarm 节点 publish 端口进行调用\n\n    ``` bash\n    ➜  ~ docker service update --publish-add 6379:6379 redis1\n    redis1\n    ➜  ~ telnet localhost 6379\n    Trying ::1...\n    Connected to localhost.\n    Escape character is '^]'.\n    set test aaa\n    +OK\n    ```\n\n- 创建一个 overlay 的网络，创建服务时，通过 `--network` 参数连接到 overlay 网络上。通过内建的 DNS 服务，可以通过 service name 解析出 task IP\n\n    ``` bash\n    ➜  ~ docker network create --driver overlay --subnet 10.0.10.0/24 sandbox\n    e7q4c68ybbw7xhrkb0at47k00\n    ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis1  docker-registry-cn.easemob.com/redis\n    0dfqszxp925id4ma9blolyjmz\n    ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis2  docker-registry-cn.easemob.com/redis\n    c3khd0snpu13ixx8popuoludx\n    ➜  ~ docker ps\n    CONTAINER ID        IMAGE                                         COMMAND                  CREATED             STATUS              PORTS               NAMES\n    4c92e01d25fd        docker-registry-cn.easemob.com/redis:latest   \"/entrypoint.sh redis\"   12 seconds ago      Up 9 seconds        6379/tcp            redis2.1.4qbw5c0hawat5rr50hgzpxj7l\n    c60b4659e768        docker-registry-cn.easemob.com/redis:latest   \"/entrypoint.sh redis\"   6 minutes ago       Up 6 minutes        6379/tcp            redis1.1.4pvn93a6i2n5teou41mddmlxr\n    ➜  ~ docker exec -it c60b4659e768 /bin/bash\n    root@c60b4659e768:/data# ping redis2\n    PING redis2 (10.0.10.4): 56 data bytes\n    64 bytes from 10.0.10.4: icmp_seq=0 ttl=64 time=0.109 ms\n    ```\n\n### 一些坑点\n\n- 截止 docker 最新版本（1.12.3），在 overlay 网络中，以 VIP 方式启动的服务，可以解析 DNS，但是无法 `ping` IP，某些依赖 `ping` 检查网络连通的程序会有问题，见 [https://github.com/docker/docker/issues/25497](https://github.com/docker/docker/issues/25497)。解决方案是启动模式换成 dnsrr （创建服务时增加参数 --endpoint-mode dnsrr），或者使用 tasks.${service_name} 的方式调用\n- 在某些操作系统（例如 Suse）上，service publish 的端口无法连接，原因不明，可能和缺少某些内核模块有关。建议使用 Centos7\n- swarm manager 会在 service 中 task 退出时重新提交 task，某些需要一次性运行的 docker image （例如环境初始化脚本的执行）endpoint 或者 cmd 需要修改成 block 形式，以免退出后被重复提交。Docker 1.13 版本允许 `docker run` 启动的容器 attach 到 swarm service 使用的 network 上，可以将一次性运行的 image 直接以 `docker run` 的方式启动\n- `docker service update --image myimage:latest` 不会拉取新镜像，即使远端有更新的版本，只能通过手动拉取镜像后重启 service 来更新服务。这个 bug 会在 docker 1.13 上被修复\n\nHave fun :)","slug":"docker-swarm-mode","published":1,"updated":"2019-01-08T16:57:49.290Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqo1fwv600092kfytoi5eahp","content":"<p>最近在公司尝试将测试环境 docker 化，由于组件比较多，考虑引入容器编排方案。首先尝试使用 docker-compose 来管理各个组件实例。可以跑通基本逻辑，但是目前没有服务发现框架，只能使用 docker 内置网络中的 DNS 发现其它服务，这限定了测试环境只能跑在单机环境上，时间久了各种 OOM。最近看到 docker 新版本附带的 swarm mode，尝试搭建了一套多机 docker 环境，感觉很满足当前的需求，并且对代码基本零侵入。简单的记录了一下搭建过程以及一些注意事项。</p>\n<h2 id=\"Swarm-mode-简介\"><a href=\"#Swarm-mode-简介\" class=\"headerlink\" title=\"Swarm mode 简介\"></a>Swarm mode 简介</h2><h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><ul>\n<li>docker swarm 是 docker 官方编排项目之一，提供将多个 docker engine 实例变成一台虚拟 docker engine 实例的能力，便于 docker 容器集群管理</li>\n<li>docker 1.12 版本推出了 swarm mode 功能，将 docker swarm 深度集成到 docker engine 中，提供了整套更为简洁的 api 对 swarm 集群进行管理。相对于原生的 docker swarm，swarm mode 部署更为简单，无需外置的服务发现框架，并且提供了容器路由服务</li>\n</ul>\n<h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><ul>\n<li>Node: node 是 swarm 集群中一个 docker engine 实例<ul>\n<li>Manager node: 对整体集群进行管理和编排，并维护整个集群</li>\n<li>Worker node: 接收 manager node 分配的 tasks，并运行，默认情况下，manager node 本身也作为一个 worker node 运行 task，可以通过改变配置让 manager node 变成一个 manager-only 的纯管理节点</li>\n</ul>\n</li>\n<li>Task: swarm 集群任务的基本单元，通常是一个 docker container 的实例</li>\n<li>Service: 由一组同类型 task 聚合而成，是 swarm 集群中主要操作对象</li>\n<li>Load balancing: swarm 集群有一套内置的负载均衡策略提供外部访问到目标容器的路由，在创建 Service 时可以发布端口到外部网络上，访问 swarm 集群任意节点该端口的请求都会被路由到该 Service</li>\n</ul>\n<h2 id=\"Swarm-mode-quick-start\"><a href=\"#Swarm-mode-quick-start\" class=\"headerlink\" title=\"Swarm mode quick start\"></a>Swarm mode quick start</h2><h3 id=\"初始化-swarm-集群\"><a href=\"#初始化-swarm-集群\" class=\"headerlink\" title=\"初始化 swarm 集群\"></a>初始化 swarm 集群</h3><ol>\n<li>初始化机器，安装 docker-engine （版本需要高于 1.12）</li>\n<li><p>选择一台机器作为 swarm manager 节点，在 console 中运行 <code>docker swarm init</code> 创建 swarm 集群，命令会返回加入集群的命令</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"> Swarm initialized: current node <span class=\"token punctuation\">(</span>c8dzd8xek2c9csoxj27ycl1nh<span class=\"token punctuation\">)</span> is now a manager.\n\n To add a worker to this swarm, run the following command:\n\n     docker swarm <span class=\"token function\">join</span> \\\n     --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n     192.168.65.2:2377\n\n To add a manager to this swarm, run <span class=\"token string\">'docker swarm join-token manager'</span> and follow the     instructions.\n</code></pre>\n</li>\n<li><p>在另一台机器上，运行提示中的命令加入集群，如果没有保存之前的提示，可以通过 <code>docker swarm join-token worker</code> 查询</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"> docker swarm <span class=\"token function\">join</span> \\\n     --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n     192.168.65.2:2377\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker info</code> 可以看到 swarm 集群的信息</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"> Swarm: active\n  NodeID: c8dzd8xek2c9csoxj27ycl1nh\n  Is Manager: <span class=\"token boolean\">true</span>\n  ClusterID: cj75fozp5effsiyuuq2dixv95\n  Managers: 1\n  Nodes: 2\n  Orchestration:\n   Task History Retention Limit: 5\n  Raft:\n   Snapshot Interval: 10000\n   Heartbeat Tick: 1\n   Election Tick: 3\n  Dispatcher:\n   Heartbeat Period: 5 seconds\n  CA Configuration:\n   Expiry Duration: 3 months\n  Node Address: 192.168.65.2\n</code></pre>\n</li>\n<li><p>在节点上运行 <code>docker swarm leave</code> 可以让当前节点离开集群，如果是管理节点，需要增加 <code>--force</code> 参数</p>\n</li>\n</ol>\n<h3 id=\"创建一个-service\"><a href=\"#创建一个-service\" class=\"headerlink\" title=\"创建一个 service\"></a>创建一个 service</h3><ol>\n<li>在 manager 节点上运行命令 <code>docker service create --replicas 1 --name redis docker-registry-cn.easemob.com/redis</code>创建 redis 服务, <code>replicas</code> 参数指定该服务中的 task 数量<ul>\n<li>如果是私有 registry，需要在 manager 节点上执行 <code>docker login</code>，然后创建服务时，增加 <code>--with-registry-auth</code> 参数将认证信息发送到 worker 节点</li>\n</ul>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service ls</code> 查看所有服务状态</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"> ID            NAME   REPLICAS      IMAGE                                     COMMAND\n 0nqfp11n2xgb  redis  1/1           docker-registry-cn.easemob.    com/redis\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service ps redis</code> 查看 redis 服务状态</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"> ID                         NAME     IMAGE                                 NODE  DESIRED STATE  CURRENT STATE         ERROR\n 3qpkmxptn8o336h161183a0vz  redis.1  docker-registry-cn.easemob.com/redis  moby  Running        Running 17 hours ago\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service update redis</code> 更新服务。例如可以用 <code>docker service update redis --publish-add 6379:6379</code> 发布 redis 服务到 swarm 集群 6379 端口上（也可以在创建服务时使用 –publish 参数发布），在 swarm 任意节点上运行 <code>redis-cli</code> 都可以连接到 redis 服务</p>\n</li>\n<li>在 manager 节点上运行 <code>docker service rm redis</code> 可以删除服务</li>\n</ol>\n<h3 id=\"Service-间网络调用\"><a href=\"#Service-间网络调用\" class=\"headerlink\" title=\"Service 间网络调用\"></a>Service 间网络调用</h3><ul>\n<li><p>如果 service publish 了端口，可以通过任意 swarm 节点 publish 端口进行调用</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  ➜  ~ docker <span class=\"token function\">service</span> update --publish-add 6379:6379 redis1\n  redis1\n  ➜  ~ telnet localhost 6379\n  Trying ::1<span class=\"token punctuation\">..</span>.\n  Connected to localhost.\n  Escape character is <span class=\"token string\">'^]'</span><span class=\"token keyword\">.</span>\n  <span class=\"token keyword\">set</span> <span class=\"token function\">test</span> aaa\n  +OK\n</code></pre>\n</li>\n<li><p>创建一个 overlay 的网络，创建服务时，通过 <code>--network</code> 参数连接到 overlay 网络上。通过内建的 DNS 服务，可以通过 service name 解析出 task IP</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">  ➜  ~ docker network create --driver overlay --subnet 10.0.10.0/24 sandbox\n  e7q4c68ybbw7xhrkb0at47k00\n  ➜  ~ docker <span class=\"token function\">service</span> create --with-registry-auth --replicas 1 --network sandbox --name redis1  docker-registry-cn.easemob.com/redis\n  0dfqszxp925id4ma9blolyjmz\n  ➜  ~ docker <span class=\"token function\">service</span> create --with-registry-auth --replicas 1 --network sandbox --name redis2  docker-registry-cn.easemob.com/redis\n  c3khd0snpu13ixx8popuoludx\n  ➜  ~ docker <span class=\"token function\">ps</span>\n  CONTAINER ID        IMAGE                                         COMMAND                  CREATED             STATUS              PORTS               NAMES\n  4c92e01d25fd        docker-registry-cn.easemob.com/redis:latest   <span class=\"token string\">\"/entrypoint.sh redis\"</span>   12 seconds ago      Up 9 seconds        6379/tcp            redis2.1.4qbw5c0hawat5rr50hgzpxj7l\n  c60b4659e768        docker-registry-cn.easemob.com/redis:latest   <span class=\"token string\">\"/entrypoint.sh redis\"</span>   6 minutes ago       Up 6 minutes        6379/tcp            redis1.1.4pvn93a6i2n5teou41mddmlxr\n  ➜  ~ docker <span class=\"token function\">exec</span> -it c60b4659e768 /bin/bash\n  root@c60b4659e768:/data<span class=\"token comment\" spellcheck=\"true\"># ping redis2</span>\n  PING redis2 <span class=\"token punctuation\">(</span>10.0.10.4<span class=\"token punctuation\">)</span>: 56 data bytes\n  64 bytes from 10.0.10.4: icmp_seq<span class=\"token operator\">=</span>0 ttl<span class=\"token operator\">=</span>64 time<span class=\"token operator\">=</span>0.109 ms\n</code></pre>\n</li>\n</ul>\n<h3 id=\"一些坑点\"><a href=\"#一些坑点\" class=\"headerlink\" title=\"一些坑点\"></a>一些坑点</h3><ul>\n<li>截止 docker 最新版本（1.12.3），在 overlay 网络中，以 VIP 方式启动的服务，可以解析 DNS，但是无法 <code>ping</code> IP，某些依赖 <code>ping</code> 检查网络连通的程序会有问题，见 <a href=\"https://github.com/docker/docker/issues/25497\" target=\"_blank\" rel=\"noopener\">https://github.com/docker/docker/issues/25497</a>。解决方案是启动模式换成 dnsrr （创建服务时增加参数 –endpoint-mode dnsrr），或者使用 tasks.${service_name} 的方式调用</li>\n<li>在某些操作系统（例如 Suse）上，service publish 的端口无法连接，原因不明，可能和缺少某些内核模块有关。建议使用 Centos7</li>\n<li>swarm manager 会在 service 中 task 退出时重新提交 task，某些需要一次性运行的 docker image （例如环境初始化脚本的执行）endpoint 或者 cmd 需要修改成 block 形式，以免退出后被重复提交。Docker 1.13 版本允许 <code>docker run</code> 启动的容器 attach 到 swarm service 使用的 network 上，可以将一次性运行的 image 直接以 <code>docker run</code> 的方式启动</li>\n<li><code>docker service update --image myimage:latest</code> 不会拉取新镜像，即使远端有更新的版本，只能通过手动拉取镜像后重启 service 来更新服务。这个 bug 会在 docker 1.13 上被修复</li>\n</ul>\n<p>Have fun :)</p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近在公司尝试将测试环境 docker 化，由于组件比较多，考虑引入容器编排方案。首先尝试使用 docker-compose 来管理各个组件实例。可以跑通基本逻辑，但是目前没有服务发现框架，只能使用 docker 内置网络中的 DNS 发现其它服务，这限定了测试环境只能跑在单机环境上，时间久了各种 OOM。最近看到 docker 新版本附带的 swarm mode，尝试搭建了一套多机 docker 环境，感觉很满足当前的需求，并且对代码基本零侵入。简单的记录了一下搭建过程以及一些注意事项。</p>\n<h2 id=\"Swarm-mode-简介\"><a href=\"#Swarm-mode-简介\" class=\"headerlink\" title=\"Swarm mode 简介\"></a>Swarm mode 简介</h2><h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><ul>\n<li>docker swarm 是 docker 官方编排项目之一，提供将多个 docker engine 实例变成一台虚拟 docker engine 实例的能力，便于 docker 容器集群管理</li>\n<li>docker 1.12 版本推出了 swarm mode 功能，将 docker swarm 深度集成到 docker engine 中，提供了整套更为简洁的 api 对 swarm 集群进行管理。相对于原生的 docker swarm，swarm mode 部署更为简单，无需外置的服务发现框架，并且提供了容器路由服务</li>\n</ul>\n<h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><ul>\n<li>Node: node 是 swarm 集群中一个 docker engine 实例<ul>\n<li>Manager node: 对整体集群进行管理和编排，并维护整个集群</li>\n<li>Worker node: 接收 manager node 分配的 tasks，并运行，默认情况下，manager node 本身也作为一个 worker node 运行 task，可以通过改变配置让 manager node 变成一个 manager-only 的纯管理节点</li>\n</ul>\n</li>\n<li>Task: swarm 集群任务的基本单元，通常是一个 docker container 的实例</li>\n<li>Service: 由一组同类型 task 聚合而成，是 swarm 集群中主要操作对象</li>\n<li>Load balancing: swarm 集群有一套内置的负载均衡策略提供外部访问到目标容器的路由，在创建 Service 时可以发布端口到外部网络上，访问 swarm 集群任意节点该端口的请求都会被路由到该 Service</li>\n</ul>\n<h2 id=\"Swarm-mode-quick-start\"><a href=\"#Swarm-mode-quick-start\" class=\"headerlink\" title=\"Swarm mode quick start\"></a>Swarm mode quick start</h2><h3 id=\"初始化-swarm-集群\"><a href=\"#初始化-swarm-集群\" class=\"headerlink\" title=\"初始化 swarm 集群\"></a>初始化 swarm 集群</h3><ol>\n<li>初始化机器，安装 docker-engine （版本需要高于 1.12）</li>\n<li><p>选择一台机器作为 swarm manager 节点，在 console 中运行 <code>docker swarm init</code> 创建 swarm 集群，命令会返回加入集群的命令</p>\n<pre><code class=\"bash\"> Swarm initialized: current node (c8dzd8xek2c9csoxj27ycl1nh) is now a manager.\n\n To add a worker to this swarm, run the following command:\n\n     docker swarm join \\\n     --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n     192.168.65.2:2377\n\n To add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the     instructions.\n</code></pre>\n</li>\n<li><p>在另一台机器上，运行提示中的命令加入集群，如果没有保存之前的提示，可以通过 <code>docker swarm join-token worker</code> 查询</p>\n<pre><code class=\"bash\"> docker swarm join \\\n     --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \\\n     192.168.65.2:2377\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker info</code> 可以看到 swarm 集群的信息</p>\n<pre><code class=\"bash\"> Swarm: active\n  NodeID: c8dzd8xek2c9csoxj27ycl1nh\n  Is Manager: true\n  ClusterID: cj75fozp5effsiyuuq2dixv95\n  Managers: 1\n  Nodes: 2\n  Orchestration:\n   Task History Retention Limit: 5\n  Raft:\n   Snapshot Interval: 10000\n   Heartbeat Tick: 1\n   Election Tick: 3\n  Dispatcher:\n   Heartbeat Period: 5 seconds\n  CA Configuration:\n   Expiry Duration: 3 months\n  Node Address: 192.168.65.2\n</code></pre>\n</li>\n<li><p>在节点上运行 <code>docker swarm leave</code> 可以让当前节点离开集群，如果是管理节点，需要增加 <code>--force</code> 参数</p>\n</li>\n</ol>\n<h3 id=\"创建一个-service\"><a href=\"#创建一个-service\" class=\"headerlink\" title=\"创建一个 service\"></a>创建一个 service</h3><ol>\n<li>在 manager 节点上运行命令 <code>docker service create --replicas 1 --name redis docker-registry-cn.easemob.com/redis</code>创建 redis 服务, <code>replicas</code> 参数指定该服务中的 task 数量<ul>\n<li>如果是私有 registry，需要在 manager 节点上执行 <code>docker login</code>，然后创建服务时，增加 <code>--with-registry-auth</code> 参数将认证信息发送到 worker 节点</li>\n</ul>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service ls</code> 查看所有服务状态</p>\n<pre><code class=\"bash\"> ID            NAME   REPLICAS      IMAGE                                     COMMAND\n 0nqfp11n2xgb  redis  1/1           docker-registry-cn.easemob.    com/redis\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service ps redis</code> 查看 redis 服务状态</p>\n<pre><code class=\"bash\"> ID                         NAME     IMAGE                                 NODE  DESIRED STATE  CURRENT STATE         ERROR\n 3qpkmxptn8o336h161183a0vz  redis.1  docker-registry-cn.easemob.com/redis  moby  Running        Running 17 hours ago\n</code></pre>\n</li>\n<li><p>在 manager 节点上运行 <code>docker service update redis</code> 更新服务。例如可以用 <code>docker service update redis --publish-add 6379:6379</code> 发布 redis 服务到 swarm 集群 6379 端口上（也可以在创建服务时使用 –publish 参数发布），在 swarm 任意节点上运行 <code>redis-cli</code> 都可以连接到 redis 服务</p>\n</li>\n<li>在 manager 节点上运行 <code>docker service rm redis</code> 可以删除服务</li>\n</ol>\n<h3 id=\"Service-间网络调用\"><a href=\"#Service-间网络调用\" class=\"headerlink\" title=\"Service 间网络调用\"></a>Service 间网络调用</h3><ul>\n<li><p>如果 service publish 了端口，可以通过任意 swarm 节点 publish 端口进行调用</p>\n<pre><code class=\"bash\">  ➜  ~ docker service update --publish-add 6379:6379 redis1\n  redis1\n  ➜  ~ telnet localhost 6379\n  Trying ::1...\n  Connected to localhost.\n  Escape character is &#39;^]&#39;.\n  set test aaa\n  +OK\n</code></pre>\n</li>\n<li><p>创建一个 overlay 的网络，创建服务时，通过 <code>--network</code> 参数连接到 overlay 网络上。通过内建的 DNS 服务，可以通过 service name 解析出 task IP</p>\n<pre><code class=\"bash\">  ➜  ~ docker network create --driver overlay --subnet 10.0.10.0/24 sandbox\n  e7q4c68ybbw7xhrkb0at47k00\n  ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis1  docker-registry-cn.easemob.com/redis\n  0dfqszxp925id4ma9blolyjmz\n  ➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis2  docker-registry-cn.easemob.com/redis\n  c3khd0snpu13ixx8popuoludx\n  ➜  ~ docker ps\n  CONTAINER ID        IMAGE                                         COMMAND                  CREATED             STATUS              PORTS               NAMES\n  4c92e01d25fd        docker-registry-cn.easemob.com/redis:latest   &quot;/entrypoint.sh redis&quot;   12 seconds ago      Up 9 seconds        6379/tcp            redis2.1.4qbw5c0hawat5rr50hgzpxj7l\n  c60b4659e768        docker-registry-cn.easemob.com/redis:latest   &quot;/entrypoint.sh redis&quot;   6 minutes ago       Up 6 minutes        6379/tcp            redis1.1.4pvn93a6i2n5teou41mddmlxr\n  ➜  ~ docker exec -it c60b4659e768 /bin/bash\n  root@c60b4659e768:/data# ping redis2\n  PING redis2 (10.0.10.4): 56 data bytes\n  64 bytes from 10.0.10.4: icmp_seq=0 ttl=64 time=0.109 ms\n</code></pre>\n</li>\n</ul>\n<h3 id=\"一些坑点\"><a href=\"#一些坑点\" class=\"headerlink\" title=\"一些坑点\"></a>一些坑点</h3><ul>\n<li>截止 docker 最新版本（1.12.3），在 overlay 网络中，以 VIP 方式启动的服务，可以解析 DNS，但是无法 <code>ping</code> IP，某些依赖 <code>ping</code> 检查网络连通的程序会有问题，见 <a href=\"https://github.com/docker/docker/issues/25497\" target=\"_blank\" rel=\"noopener\">https://github.com/docker/docker/issues/25497</a>。解决方案是启动模式换成 dnsrr （创建服务时增加参数 –endpoint-mode dnsrr），或者使用 tasks.${service_name} 的方式调用</li>\n<li>在某些操作系统（例如 Suse）上，service publish 的端口无法连接，原因不明，可能和缺少某些内核模块有关。建议使用 Centos7</li>\n<li>swarm manager 会在 service 中 task 退出时重新提交 task，某些需要一次性运行的 docker image （例如环境初始化脚本的执行）endpoint 或者 cmd 需要修改成 block 形式，以免退出后被重复提交。Docker 1.13 版本允许 <code>docker run</code> 启动的容器 attach 到 swarm service 使用的 network 上，可以将一次性运行的 image 直接以 <code>docker run</code> 的方式启动</li>\n<li><code>docker service update --image myimage:latest</code> 不会拉取新镜像，即使远端有更新的版本，只能通过手动拉取镜像后重启 service 来更新服务。这个 bug 会在 docker 1.13 上被修复</li>\n</ul>\n<p>Have fun :)</p>\n"},{"title":"Storm 在线业务实践-集群空闲 CPU 飙高问题排查","url":"8.html","id":"8","date":"2015-07-18T09:51:53.000Z","_content":"\n最近将公司的在线业务迁移到 Storm 集群上，上线后遇到低峰期 CPU 耗费严重的情况。在解决问题的过程中深入了解了 Storm 的内部实现原理，并且解决了一个 Storm 0.9-0.10版本一直存在的严重 bug，目前代码已经合并到了 Storm 新版本中，在这篇文章里会介绍这个问题出现的场景、分析思路、解决的方式和一些个人的收获。\n\n## 背景\n\n首先简单介绍一下 Storm，老司机可以直接跳过这段。 Storm 是 Twitter 开源的一个大数据处理框架，专注于流式数据的处理。Storm通过创建拓扑结构（Topology）来转换数据流。和 Hadoop 的作业（Job）不同，Topology 会持续转换数据，除非被集群关闭。 下图是一个简单的 Storm Topology 结构图。\n\n![topology](/images/storm.gif)\n\n可以看出Topology是由不同组件（Component）串/并联形成的有向图。数据元组（Tuple）会在Component之间通过数据流的形式进行有向传递。Component有两种\n\n- Spout：Tuple 来源节点，持续不断的产生Tuple，形成数据流\n- Bolt：Tuple 处理节点，处理收到的 Tuple，如果有需要，也可以生成新的 Tuple 传递到其他 Bolt\n\n目前业界主要在离线或者对实时性要求不高业务中使用 Storm。随着 Storm 版本的更迭，可靠性和实时性在逐渐增强，已经有运行在线业务的能力。因此我们尝试将一些实时性要求在百毫秒级的在线业务迁入Storm 集群。\n\n## 现象\n\n1. 某次高峰时，Storm 上的一个业务拓扑频繁出现消息处理延迟。延时达到了 10s 甚至更高。查看高峰时的物理机指标监控，CPU、内存和 IO 都有很大的余量。判断是随着业务增长，服务流量逐渐增加，某个 Bolt 之前设置的并行度不够，导致消息堆积了。\n2. 临时增加该 Bolt 并行度，解决了延迟的问题，但是第二天的低峰期，服务突然报警，CPU 负载过高，达到了 100%。\n\n## 排查\n\n1. 用 Top 看了下 CPU 占用，系统调用占用了 70% 左右。再用 [wtool](https://github.com/qdaxb/wtool) 对 Storm 的工作进程进行分析，找到了 CPU 占用最高的线程\n\n    ``` java\n    java.lang.Thread.State: TIMED_WAITING (parking)\n    at sun.misc.Unsafe.park(Native Method)\n    - parking to wait for  <0x0000000640a248f8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)\n    at com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:87)\n    at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:54)\n    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:97)\n    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80)\n    at backtype.storm.daemon.executor$fn__3441$fn__3453$fn__3500.invoke(executor.clj:748)\n    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463)\n    at clojure.lang.AFn.run(AFn.java:24)\n    at java.lang.Thread.run(Thread.java:745)\n    ```\n    我们可以看到这些线程都在信号量上等待。调用的来源是 `disruptor$consume_batch_when_available`。\n\n2. disruptor 是 Storm 内部消息队列的封装。所以先了解了一下 Storm 内部的消息传输机制。\n\n    ![Storm内部消息传输机制](/images/storm-messaging.png)（图片来源[Understanding the Internal Message Buffers of Storm](http://www.michael-noll.com/blog/2013/06/21/understanding-storm-internal-message-buffers/)）\n\n    Storm 的工作节点称为 Worker（其实就是一个JVM 进程）。不同 Worker 之间通过 Netty（旧版 Storm 使用 ZeroMQ）进行通讯。每个Worker 内部包含一组 Executor。Storm 会为拓扑中的每个 Component 都分配一个 Executor。在实际的数据处理流程中，数据以消息的形式在 Executor 之间流转。Executor 会循环调用绑定的 Component 的处理方法来处理收到的消息。 Executor 之间的消息传输使用队列作为消息管道。Storm 会给每个 Executor 分配两个队列和两个处理线程。\n\n      - 工作线程：读取接收队列，对消息进行处理，如果产生新的消息，会写入发送队列\n      - 发送线程：读取发送队列，将消息发送其他Executor\n\n   当Executor的发送线程发送消息时，会判断目标Executor是否在同一Worker内，如果是，则直接将消息写入目标Executor的接收队列，如果不是，则将消息写入Worker的传输队列，通过网络发送。 Executor工作/发送线程读取队列的代码如下，这里会循环调用consume-batch-when-available读取队列中的消息，并对消息进行处理。\n\n    ``` clojure\n    (async-loop\n      (fn []\n        ...\n        (disruptor/consume-batch-when-available receive-queue event-handler)\n      ...\n    ))\n    ```\n\n3. 我们再来看一下 `consume_batch_when_available` 这个函数里做了什么。\n\n    ``` clojure\n    (defn consume-batch-when-available\n      [^DisruptorQueue queue handler]\n      (.consumeBatchWhenAvailable queue handler))\n    ```\n    前面提到 Storm 使用队列作为消息管道。Storm 作为流式大数据处理框架，对消息传输的性能很敏感，因此使用了高效内存队列 Disruptor Queue 作为消息队列。\n\n    ![storm-simple](/images/storm-simple.png)\n\n    Disruptor Queue 是 LMAX 开源的一个无锁内存队列。内部实现如下。\n\n    ![Disruptor queue](/images/Models.png)\n    （图片来源 [Disruptor queue Introduction](https://github.com/LMAX-Exchange/disruptor/wiki/Introduction))\n\n    Disruptor Queue 通过 Sequencer 来管理队列，Sequencer 内部使用 RingBuffer 存储消息。RingBuffer 中消息的位置使用 Sequence 表示。队列的生产消费过程如下\n\n      - Sequencer 使用一个 Cursor 来保存写入位置。\n      - 每个 Consumer 都会维护一个消费位置，并注册到 Sequencer。\n      - Consumer 通过 SequenceBarrier 和 Sequencer 进行交互。Consumer 每次消费时，SequenceBarrier 会比较消费位置和 Cursor 来判断是否有可用消息：如果没有，**会按照设定的策略等待消息**；如果有，则读取消息，修改消费位置。\n      - Producer 在写入前会查看所有消费者的消费位置，在有可用位置时会写入消息，更新 Cursor。\n\n   查看 `DisruptorQueue.consumeBatchWhenAvailable` 实现如下\n\n    ``` java\n    final long nextSequence = _consumer.get() + 1;\n    final long availableSequence = _barrier.waitFor(nextSequence, 10, TimeUnit.MILLISECONDS);\n    if (availableSequence >= nextSequence) {\n        consumeBatchToCursor(availableSequence, handler);\n    }\n    ```\n\n    继续查看 `_barrier.waitFor` 方法\n\n    ``` java\n    public long waitFor(final long sequence, final long timeout, final TimeUnit units) throws AlertException, InterruptedException {\n        checkAlert();\n        return waitStrategy.waitFor(sequence, cursorSequence, dependentSequences, this, timeout, units);\n    }\n    ```\n\n   Disruptor Queue 为消费者提供了若干种消息等待策略\n\n      - `BlockingWaitStrategy`：阻塞等待，CPU 占用小，但是会切换线程，延迟较高\n      - `BusySpinWaitStrategy`：自旋等待，CPU 占用高，但是无需切换线程，延迟低\n      - `YieldingWaitStrategy`：先自旋等待，然后使用 Thread.yield() 唤醒其他线程，CPU 占用和延迟比较均衡\n      - `SleepingWaitStrategy`：先自旋，然后`Thread.yield()`，最后调用 `LockSupport.parkNanos(1L)`，CPU 占用和延迟比较均衡\n\n   Storm 的默认等待策略为 `BlockingWaitStrategy`。`BlockingWaitStrategy` 的 `waitFor` 函数实现如下\n\n    ``` java\n    if ((availableSequence = cursor.get()) < sequence) {\n            lock.lock();\n            try {\n                ++numWaiters;\n                while ((availableSequence = cursor.get()) < sequence) {\n                    barrier.checkAlert();\n\n                    if (!processorNotifyCondition.await(timeout, sourceUnit)) {\n                        break;\n                    }\n                }\n            }\n            finally {\n                --numWaiters;\n                lock.unlock();\n            }\n    }\n    ```\n    `BlockingWaitStrategy` 内部使用信号量来阻塞 Consumer，当 await 超时后，Consumer 线程会被自动唤醒，继续循环查询可用消息。\n4. 而`DisruptorQueue.consumeBatchWhenAvailable` 方法中可以看到，Storm 此处设置超时为 10ms。推测在没有消息或者消息量较少时，Executor 在消费队列时会被阻塞，由于超时时间很短，工作线程会频繁超时，`consumeBatchWhenAvailable` 会被频繁调用，导致 CPU 占用飙高。尝试将 10ms 修改成 100ms，编译 Storm 后重新部署集群，使用 Storm 的 demo 拓扑，将 bolt 并发度调到 1000，修改 spout 代码为 10s 发一条消息。经测试 CPU 占用大幅减少。再将 100ms 改成 1s，测试 CPU 占用基本降为零。\n5. 但是随着调高超时，测试时并没有发现消息处理有延时。继续查看 `BlockingWaitStrategy` 代码，发现 Disruptor Queue 的 Producer 在写入消息后会唤醒等待的 Consumer。\n\n    ``` java\n    if (0 != numWaiters)\n    {\n        lock.lock();\n        try\n        {\n            processorNotifyCondition.signalAll();\n        }\n        finally\n        {\n            lock.unlock();\n        }\n    }\n    ```\n\n    这样，Storm 的 10ms 超时就很奇怪了，没有减少消息延时，反而增加了系统负载。带着这个疑问查看代码的上下文，发现在构造 `DisruptorQueue` 对象时有这么一句注释\n\n    ```clojure\n    ;; :block strategy requires using a timeout on waitFor (implemented in DisruptorQueue), as sometimes the consumer stays blocked even when there's an item on the queue.\n    (defnk disruptor-queue\n        [^String queue-name buffer-size :claim-strategy :multi-threaded :wait-strategy :block]\n        (DisruptorQueue. queue-name\n                    ((CLAIM-STRATEGY claim-strategy) buffer-size)\n                    (mk-wait-strategy wait-strategy)))\n    ```\n    Storm 使用的 Disruptor Queue 版本为2.10.1。查看 Disruptor Queue 的change log，发现该版本的 `BlockingWaitStrategy` 有潜在的并发问题，可能导致某条消息在写入时没有唤醒等待的消费者。\n\n    > 2.10.2 Released (21-Aug-2012)\n    > - Bug fix, potential race     condition in BlockingWaitStrategy.\n    > - Bug fix set initial     SequenceGroup value to -1 (Issue     #27).\n    > - Deprecate timeout methods that will be removed in version 3.\n\n    因此 Storm 使用了短超时，这样在出现并发问题时，没有被唤醒的消费方也会很快因为超时重新查询可用消息，防止出现消息延时。 这样如果直接修改超时到 1000ms，一旦出现并发问题，最坏情况下消息会延迟 1000ms。在权衡性能和延时之后，我们在 Storm 的配置文件中增加配置项来修改超时参数。这样使用者可以自己选择保证低延时还是低 CPU 占用率。\n6. 就 `BlockingWaitStrategy` 的潜在并发问题咨询了Disruptor Queue的作者，得知2.10.4版本已经修复了这个并发问题（[Race condition in 2.10.1 release](https://github.com/LMAX-Exchange/disruptor/issues/119) ）。将 Storm 依赖升级到此版本。但是对 Disruptor Queue 的 2.10.1 做了并发测试，无法复现这个并发问题，因此也无法确定 2.10.4 是否彻底修复。谨慎起见，在升级依赖的同时保留了之前的超时配置项，并将默认超时调整为 1000ms。经测试，在集群空闲时 CPU 占用正常，并且压测也没有出现消息延时。\n\n### 总结\n\n1. 关于集群空闲CPU反而飙高的问题，已经向Storm社区提交PR并且已被接受 [[STORM-935] Update Disruptor queue version to 2.10.4](https://github.com/apache/storm/pull/630)。在线业务流量通常起伏很大，如果被这个问题困扰，可以考虑应用此 patch。\n2. Storm UI 中可以看到很多有用的信息，但是缺乏记录，最好对其进行二次开发（或者直接读取 ZooKeeper 中信息），记录每个时间段的数据，方便分析集群和拓扑运行状况。","source":"_posts/storm-cpu-overload.md","raw":"---\ntitle: Storm 在线业务实践-集群空闲 CPU 飙高问题排查\ntags:\n  - Storm\nurl: 8.html\nid: 8\ncategories:\n  - Tech\ndate: 2015-07-18 17:51:53\n---\n\n最近将公司的在线业务迁移到 Storm 集群上，上线后遇到低峰期 CPU 耗费严重的情况。在解决问题的过程中深入了解了 Storm 的内部实现原理，并且解决了一个 Storm 0.9-0.10版本一直存在的严重 bug，目前代码已经合并到了 Storm 新版本中，在这篇文章里会介绍这个问题出现的场景、分析思路、解决的方式和一些个人的收获。\n\n## 背景\n\n首先简单介绍一下 Storm，老司机可以直接跳过这段。 Storm 是 Twitter 开源的一个大数据处理框架，专注于流式数据的处理。Storm通过创建拓扑结构（Topology）来转换数据流。和 Hadoop 的作业（Job）不同，Topology 会持续转换数据，除非被集群关闭。 下图是一个简单的 Storm Topology 结构图。\n\n![topology](/images/storm.gif)\n\n可以看出Topology是由不同组件（Component）串/并联形成的有向图。数据元组（Tuple）会在Component之间通过数据流的形式进行有向传递。Component有两种\n\n- Spout：Tuple 来源节点，持续不断的产生Tuple，形成数据流\n- Bolt：Tuple 处理节点，处理收到的 Tuple，如果有需要，也可以生成新的 Tuple 传递到其他 Bolt\n\n目前业界主要在离线或者对实时性要求不高业务中使用 Storm。随着 Storm 版本的更迭，可靠性和实时性在逐渐增强，已经有运行在线业务的能力。因此我们尝试将一些实时性要求在百毫秒级的在线业务迁入Storm 集群。\n\n## 现象\n\n1. 某次高峰时，Storm 上的一个业务拓扑频繁出现消息处理延迟。延时达到了 10s 甚至更高。查看高峰时的物理机指标监控，CPU、内存和 IO 都有很大的余量。判断是随着业务增长，服务流量逐渐增加，某个 Bolt 之前设置的并行度不够，导致消息堆积了。\n2. 临时增加该 Bolt 并行度，解决了延迟的问题，但是第二天的低峰期，服务突然报警，CPU 负载过高，达到了 100%。\n\n## 排查\n\n1. 用 Top 看了下 CPU 占用，系统调用占用了 70% 左右。再用 [wtool](https://github.com/qdaxb/wtool) 对 Storm 的工作进程进行分析，找到了 CPU 占用最高的线程\n\n    ``` java\n    java.lang.Thread.State: TIMED_WAITING (parking)\n    at sun.misc.Unsafe.park(Native Method)\n    - parking to wait for  <0x0000000640a248f8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)\n    at com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:87)\n    at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:54)\n    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:97)\n    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80)\n    at backtype.storm.daemon.executor$fn__3441$fn__3453$fn__3500.invoke(executor.clj:748)\n    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463)\n    at clojure.lang.AFn.run(AFn.java:24)\n    at java.lang.Thread.run(Thread.java:745)\n    ```\n    我们可以看到这些线程都在信号量上等待。调用的来源是 `disruptor$consume_batch_when_available`。\n\n2. disruptor 是 Storm 内部消息队列的封装。所以先了解了一下 Storm 内部的消息传输机制。\n\n    ![Storm内部消息传输机制](/images/storm-messaging.png)（图片来源[Understanding the Internal Message Buffers of Storm](http://www.michael-noll.com/blog/2013/06/21/understanding-storm-internal-message-buffers/)）\n\n    Storm 的工作节点称为 Worker（其实就是一个JVM 进程）。不同 Worker 之间通过 Netty（旧版 Storm 使用 ZeroMQ）进行通讯。每个Worker 内部包含一组 Executor。Storm 会为拓扑中的每个 Component 都分配一个 Executor。在实际的数据处理流程中，数据以消息的形式在 Executor 之间流转。Executor 会循环调用绑定的 Component 的处理方法来处理收到的消息。 Executor 之间的消息传输使用队列作为消息管道。Storm 会给每个 Executor 分配两个队列和两个处理线程。\n\n      - 工作线程：读取接收队列，对消息进行处理，如果产生新的消息，会写入发送队列\n      - 发送线程：读取发送队列，将消息发送其他Executor\n\n   当Executor的发送线程发送消息时，会判断目标Executor是否在同一Worker内，如果是，则直接将消息写入目标Executor的接收队列，如果不是，则将消息写入Worker的传输队列，通过网络发送。 Executor工作/发送线程读取队列的代码如下，这里会循环调用consume-batch-when-available读取队列中的消息，并对消息进行处理。\n\n    ``` clojure\n    (async-loop\n      (fn []\n        ...\n        (disruptor/consume-batch-when-available receive-queue event-handler)\n      ...\n    ))\n    ```\n\n3. 我们再来看一下 `consume_batch_when_available` 这个函数里做了什么。\n\n    ``` clojure\n    (defn consume-batch-when-available\n      [^DisruptorQueue queue handler]\n      (.consumeBatchWhenAvailable queue handler))\n    ```\n    前面提到 Storm 使用队列作为消息管道。Storm 作为流式大数据处理框架，对消息传输的性能很敏感，因此使用了高效内存队列 Disruptor Queue 作为消息队列。\n\n    ![storm-simple](/images/storm-simple.png)\n\n    Disruptor Queue 是 LMAX 开源的一个无锁内存队列。内部实现如下。\n\n    ![Disruptor queue](/images/Models.png)\n    （图片来源 [Disruptor queue Introduction](https://github.com/LMAX-Exchange/disruptor/wiki/Introduction))\n\n    Disruptor Queue 通过 Sequencer 来管理队列，Sequencer 内部使用 RingBuffer 存储消息。RingBuffer 中消息的位置使用 Sequence 表示。队列的生产消费过程如下\n\n      - Sequencer 使用一个 Cursor 来保存写入位置。\n      - 每个 Consumer 都会维护一个消费位置，并注册到 Sequencer。\n      - Consumer 通过 SequenceBarrier 和 Sequencer 进行交互。Consumer 每次消费时，SequenceBarrier 会比较消费位置和 Cursor 来判断是否有可用消息：如果没有，**会按照设定的策略等待消息**；如果有，则读取消息，修改消费位置。\n      - Producer 在写入前会查看所有消费者的消费位置，在有可用位置时会写入消息，更新 Cursor。\n\n   查看 `DisruptorQueue.consumeBatchWhenAvailable` 实现如下\n\n    ``` java\n    final long nextSequence = _consumer.get() + 1;\n    final long availableSequence = _barrier.waitFor(nextSequence, 10, TimeUnit.MILLISECONDS);\n    if (availableSequence >= nextSequence) {\n        consumeBatchToCursor(availableSequence, handler);\n    }\n    ```\n\n    继续查看 `_barrier.waitFor` 方法\n\n    ``` java\n    public long waitFor(final long sequence, final long timeout, final TimeUnit units) throws AlertException, InterruptedException {\n        checkAlert();\n        return waitStrategy.waitFor(sequence, cursorSequence, dependentSequences, this, timeout, units);\n    }\n    ```\n\n   Disruptor Queue 为消费者提供了若干种消息等待策略\n\n      - `BlockingWaitStrategy`：阻塞等待，CPU 占用小，但是会切换线程，延迟较高\n      - `BusySpinWaitStrategy`：自旋等待，CPU 占用高，但是无需切换线程，延迟低\n      - `YieldingWaitStrategy`：先自旋等待，然后使用 Thread.yield() 唤醒其他线程，CPU 占用和延迟比较均衡\n      - `SleepingWaitStrategy`：先自旋，然后`Thread.yield()`，最后调用 `LockSupport.parkNanos(1L)`，CPU 占用和延迟比较均衡\n\n   Storm 的默认等待策略为 `BlockingWaitStrategy`。`BlockingWaitStrategy` 的 `waitFor` 函数实现如下\n\n    ``` java\n    if ((availableSequence = cursor.get()) < sequence) {\n            lock.lock();\n            try {\n                ++numWaiters;\n                while ((availableSequence = cursor.get()) < sequence) {\n                    barrier.checkAlert();\n\n                    if (!processorNotifyCondition.await(timeout, sourceUnit)) {\n                        break;\n                    }\n                }\n            }\n            finally {\n                --numWaiters;\n                lock.unlock();\n            }\n    }\n    ```\n    `BlockingWaitStrategy` 内部使用信号量来阻塞 Consumer，当 await 超时后，Consumer 线程会被自动唤醒，继续循环查询可用消息。\n4. 而`DisruptorQueue.consumeBatchWhenAvailable` 方法中可以看到，Storm 此处设置超时为 10ms。推测在没有消息或者消息量较少时，Executor 在消费队列时会被阻塞，由于超时时间很短，工作线程会频繁超时，`consumeBatchWhenAvailable` 会被频繁调用，导致 CPU 占用飙高。尝试将 10ms 修改成 100ms，编译 Storm 后重新部署集群，使用 Storm 的 demo 拓扑，将 bolt 并发度调到 1000，修改 spout 代码为 10s 发一条消息。经测试 CPU 占用大幅减少。再将 100ms 改成 1s，测试 CPU 占用基本降为零。\n5. 但是随着调高超时，测试时并没有发现消息处理有延时。继续查看 `BlockingWaitStrategy` 代码，发现 Disruptor Queue 的 Producer 在写入消息后会唤醒等待的 Consumer。\n\n    ``` java\n    if (0 != numWaiters)\n    {\n        lock.lock();\n        try\n        {\n            processorNotifyCondition.signalAll();\n        }\n        finally\n        {\n            lock.unlock();\n        }\n    }\n    ```\n\n    这样，Storm 的 10ms 超时就很奇怪了，没有减少消息延时，反而增加了系统负载。带着这个疑问查看代码的上下文，发现在构造 `DisruptorQueue` 对象时有这么一句注释\n\n    ```clojure\n    ;; :block strategy requires using a timeout on waitFor (implemented in DisruptorQueue), as sometimes the consumer stays blocked even when there's an item on the queue.\n    (defnk disruptor-queue\n        [^String queue-name buffer-size :claim-strategy :multi-threaded :wait-strategy :block]\n        (DisruptorQueue. queue-name\n                    ((CLAIM-STRATEGY claim-strategy) buffer-size)\n                    (mk-wait-strategy wait-strategy)))\n    ```\n    Storm 使用的 Disruptor Queue 版本为2.10.1。查看 Disruptor Queue 的change log，发现该版本的 `BlockingWaitStrategy` 有潜在的并发问题，可能导致某条消息在写入时没有唤醒等待的消费者。\n\n    > 2.10.2 Released (21-Aug-2012)\n    > - Bug fix, potential race     condition in BlockingWaitStrategy.\n    > - Bug fix set initial     SequenceGroup value to -1 (Issue     #27).\n    > - Deprecate timeout methods that will be removed in version 3.\n\n    因此 Storm 使用了短超时，这样在出现并发问题时，没有被唤醒的消费方也会很快因为超时重新查询可用消息，防止出现消息延时。 这样如果直接修改超时到 1000ms，一旦出现并发问题，最坏情况下消息会延迟 1000ms。在权衡性能和延时之后，我们在 Storm 的配置文件中增加配置项来修改超时参数。这样使用者可以自己选择保证低延时还是低 CPU 占用率。\n6. 就 `BlockingWaitStrategy` 的潜在并发问题咨询了Disruptor Queue的作者，得知2.10.4版本已经修复了这个并发问题（[Race condition in 2.10.1 release](https://github.com/LMAX-Exchange/disruptor/issues/119) ）。将 Storm 依赖升级到此版本。但是对 Disruptor Queue 的 2.10.1 做了并发测试，无法复现这个并发问题，因此也无法确定 2.10.4 是否彻底修复。谨慎起见，在升级依赖的同时保留了之前的超时配置项，并将默认超时调整为 1000ms。经测试，在集群空闲时 CPU 占用正常，并且压测也没有出现消息延时。\n\n### 总结\n\n1. 关于集群空闲CPU反而飙高的问题，已经向Storm社区提交PR并且已被接受 [[STORM-935] Update Disruptor queue version to 2.10.4](https://github.com/apache/storm/pull/630)。在线业务流量通常起伏很大，如果被这个问题困扰，可以考虑应用此 patch。\n2. Storm UI 中可以看到很多有用的信息，但是缺乏记录，最好对其进行二次开发（或者直接读取 ZooKeeper 中信息），记录每个时间段的数据，方便分析集群和拓扑运行状况。","slug":"storm-cpu-overload","published":1,"updated":"2019-01-08T16:57:49.291Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqo1fwv9000a2kfydoucrhhi","content":"<p>最近将公司的在线业务迁移到 Storm 集群上，上线后遇到低峰期 CPU 耗费严重的情况。在解决问题的过程中深入了解了 Storm 的内部实现原理，并且解决了一个 Storm 0.9-0.10版本一直存在的严重 bug，目前代码已经合并到了 Storm 新版本中，在这篇文章里会介绍这个问题出现的场景、分析思路、解决的方式和一些个人的收获。</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>首先简单介绍一下 Storm，老司机可以直接跳过这段。 Storm 是 Twitter 开源的一个大数据处理框架，专注于流式数据的处理。Storm通过创建拓扑结构（Topology）来转换数据流。和 Hadoop 的作业（Job）不同，Topology 会持续转换数据，除非被集群关闭。 下图是一个简单的 Storm Topology 结构图。</p>\n<p><img src=\"/images/storm.gif\" alt=\"topology\"></p>\n<p>可以看出Topology是由不同组件（Component）串/并联形成的有向图。数据元组（Tuple）会在Component之间通过数据流的形式进行有向传递。Component有两种</p>\n<ul>\n<li>Spout：Tuple 来源节点，持续不断的产生Tuple，形成数据流</li>\n<li>Bolt：Tuple 处理节点，处理收到的 Tuple，如果有需要，也可以生成新的 Tuple 传递到其他 Bolt</li>\n</ul>\n<p>目前业界主要在离线或者对实时性要求不高业务中使用 Storm。随着 Storm 版本的更迭，可靠性和实时性在逐渐增强，已经有运行在线业务的能力。因此我们尝试将一些实时性要求在百毫秒级的在线业务迁入Storm 集群。</p>\n<h2 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h2><ol>\n<li>某次高峰时，Storm 上的一个业务拓扑频繁出现消息处理延迟。延时达到了 10s 甚至更高。查看高峰时的物理机指标监控，CPU、内存和 IO 都有很大的余量。判断是随着业务增长，服务流量逐渐增加，某个 Bolt 之前设置的并行度不够，导致消息堆积了。</li>\n<li>临时增加该 Bolt 并行度，解决了延迟的问题，但是第二天的低峰期，服务突然报警，CPU 负载过高，达到了 100%。</li>\n</ol>\n<h2 id=\"排查\"><a href=\"#排查\" class=\"headerlink\" title=\"排查\"></a>排查</h2><ol>\n<li><p>用 Top 看了下 CPU 占用，系统调用占用了 70% 左右。再用 <a href=\"https://github.com/qdaxb/wtool\" target=\"_blank\" rel=\"noopener\">wtool</a> 对 Storm 的工作进程进行分析，找到了 CPU 占用最高的线程</p>\n<pre class=\" language-java\"><code class=\"language-java\"> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span>State<span class=\"token operator\">:</span> <span class=\"token function\">TIMED_WAITING</span> <span class=\"token punctuation\">(</span>parking<span class=\"token punctuation\">)</span>\n at sun<span class=\"token punctuation\">.</span>misc<span class=\"token punctuation\">.</span>Unsafe<span class=\"token punctuation\">.</span><span class=\"token function\">park</span><span class=\"token punctuation\">(</span>Native Method<span class=\"token punctuation\">)</span>\n <span class=\"token operator\">-</span> parking to wait <span class=\"token keyword\">for</span>  <span class=\"token operator\">&lt;</span><span class=\"token number\">0x0000000640a248f8</span><span class=\"token operator\">></span> <span class=\"token punctuation\">(</span>a java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span>AbstractQueuedSynchronizer$ConditionObject<span class=\"token punctuation\">)</span>\n at java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span>LockSupport<span class=\"token punctuation\">.</span><span class=\"token function\">parkNanos</span><span class=\"token punctuation\">(</span>LockSupport<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">215</span><span class=\"token punctuation\">)</span>\n at java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span>AbstractQueuedSynchronizer$ConditionObject<span class=\"token punctuation\">.</span><span class=\"token function\">await</span><span class=\"token punctuation\">(</span>AbstractQueuedSynchronizer<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">2163</span><span class=\"token punctuation\">)</span>\n at com<span class=\"token punctuation\">.</span>lmax<span class=\"token punctuation\">.</span>disruptor<span class=\"token punctuation\">.</span>BlockingWaitStrategy<span class=\"token punctuation\">.</span><span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span>BlockingWaitStrategy<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">87</span><span class=\"token punctuation\">)</span>\n at com<span class=\"token punctuation\">.</span>lmax<span class=\"token punctuation\">.</span>disruptor<span class=\"token punctuation\">.</span>ProcessingSequenceBarrier<span class=\"token punctuation\">.</span><span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span>ProcessingSequenceBarrier<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">54</span><span class=\"token punctuation\">)</span>\n at backtype<span class=\"token punctuation\">.</span>storm<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>DisruptorQueue<span class=\"token punctuation\">.</span><span class=\"token function\">consumeBatchWhenAvailable</span><span class=\"token punctuation\">(</span>DisruptorQueue<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">97</span><span class=\"token punctuation\">)</span>\n at backtype<span class=\"token punctuation\">.</span>storm<span class=\"token punctuation\">.</span>disruptor$consume_batch_when_available<span class=\"token punctuation\">.</span><span class=\"token function\">invoke</span><span class=\"token punctuation\">(</span>disruptor<span class=\"token punctuation\">.</span>clj<span class=\"token operator\">:</span><span class=\"token number\">80</span><span class=\"token punctuation\">)</span>\n at backtype<span class=\"token punctuation\">.</span>storm<span class=\"token punctuation\">.</span>daemon<span class=\"token punctuation\">.</span>executor$fn__3441$fn__3453$fn__3500<span class=\"token punctuation\">.</span><span class=\"token function\">invoke</span><span class=\"token punctuation\">(</span>executor<span class=\"token punctuation\">.</span>clj<span class=\"token operator\">:</span><span class=\"token number\">748</span><span class=\"token punctuation\">)</span>\n at backtype<span class=\"token punctuation\">.</span>storm<span class=\"token punctuation\">.</span>util$async_loop$fn__464<span class=\"token punctuation\">.</span><span class=\"token function\">invoke</span><span class=\"token punctuation\">(</span>util<span class=\"token punctuation\">.</span>clj<span class=\"token operator\">:</span><span class=\"token number\">463</span><span class=\"token punctuation\">)</span>\n at clojure<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>AFn<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>AFn<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">24</span><span class=\"token punctuation\">)</span>\n at java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>Thread<span class=\"token punctuation\">.</span>java<span class=\"token operator\">:</span><span class=\"token number\">745</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p> 我们可以看到这些线程都在信号量上等待。调用的来源是 <code>disruptor$consume_batch_when_available</code>。</p>\n</li>\n<li><p>disruptor 是 Storm 内部消息队列的封装。所以先了解了一下 Storm 内部的消息传输机制。</p>\n<p> <img src=\"/images/storm-messaging.png\" alt=\"Storm内部消息传输机制\">（图片来源<a href=\"http://www.michael-noll.com/blog/2013/06/21/understanding-storm-internal-message-buffers/\" target=\"_blank\" rel=\"noopener\">Understanding the Internal Message Buffers of Storm</a>）</p>\n<p> Storm 的工作节点称为 Worker（其实就是一个JVM 进程）。不同 Worker 之间通过 Netty（旧版 Storm 使用 ZeroMQ）进行通讯。每个Worker 内部包含一组 Executor。Storm 会为拓扑中的每个 Component 都分配一个 Executor。在实际的数据处理流程中，数据以消息的形式在 Executor 之间流转。Executor 会循环调用绑定的 Component 的处理方法来处理收到的消息。 Executor 之间的消息传输使用队列作为消息管道。Storm 会给每个 Executor 分配两个队列和两个处理线程。</p>\n<ul>\n<li>工作线程：读取接收队列，对消息进行处理，如果产生新的消息，会写入发送队列</li>\n<li>发送线程：读取发送队列，将消息发送其他Executor</li>\n</ul>\n<p>当Executor的发送线程发送消息时，会判断目标Executor是否在同一Worker内，如果是，则直接将消息写入目标Executor的接收队列，如果不是，则将消息写入Worker的传输队列，通过网络发送。 Executor工作/发送线程读取队列的代码如下，这里会循环调用consume-batch-when-available读取队列中的消息，并对消息进行处理。</p>\n<pre class=\" language-clojure\"><code class=\"language-clojure\"> (async-loop\n   (fn []\n     ...\n     (disruptor/consume-batch-when-available receive-queue event-handler)\n   ...\n ))\n</code></pre>\n</li>\n<li><p>我们再来看一下 <code>consume_batch_when_available</code> 这个函数里做了什么。</p>\n<pre class=\" language-clojure\"><code class=\"language-clojure\"> (defn consume-batch-when-available\n   [^DisruptorQueue queue handler]\n   (.consumeBatchWhenAvailable queue handler))\n</code></pre>\n<p> 前面提到 Storm 使用队列作为消息管道。Storm 作为流式大数据处理框架，对消息传输的性能很敏感，因此使用了高效内存队列 Disruptor Queue 作为消息队列。</p>\n<p> <img src=\"/images/storm-simple.png\" alt=\"storm-simple\"></p>\n<p> Disruptor Queue 是 LMAX 开源的一个无锁内存队列。内部实现如下。</p>\n<p> <img src=\"/images/Models.png\" alt=\"Disruptor queue\"><br> （图片来源 <a href=\"https://github.com/LMAX-Exchange/disruptor/wiki/Introduction\" target=\"_blank\" rel=\"noopener\">Disruptor queue Introduction</a>)</p>\n<p> Disruptor Queue 通过 Sequencer 来管理队列，Sequencer 内部使用 RingBuffer 存储消息。RingBuffer 中消息的位置使用 Sequence 表示。队列的生产消费过程如下</p>\n<ul>\n<li>Sequencer 使用一个 Cursor 来保存写入位置。</li>\n<li>每个 Consumer 都会维护一个消费位置，并注册到 Sequencer。</li>\n<li>Consumer 通过 SequenceBarrier 和 Sequencer 进行交互。Consumer 每次消费时，SequenceBarrier 会比较消费位置和 Cursor 来判断是否有可用消息：如果没有，<strong>会按照设定的策略等待消息</strong>；如果有，则读取消息，修改消费位置。</li>\n<li>Producer 在写入前会查看所有消费者的消费位置，在有可用位置时会写入消息，更新 Cursor。</li>\n</ul>\n<p>查看 <code>DisruptorQueue.consumeBatchWhenAvailable</code> 实现如下</p>\n<pre class=\" language-java\"><code class=\"language-java\"> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> nextSequence <span class=\"token operator\">=</span> _consumer<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> availableSequence <span class=\"token operator\">=</span> _barrier<span class=\"token punctuation\">.</span><span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span>nextSequence<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>MILLISECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>availableSequence <span class=\"token operator\">>=</span> nextSequence<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n     <span class=\"token function\">consumeBatchToCursor</span><span class=\"token punctuation\">(</span>availableSequence<span class=\"token punctuation\">,</span> handler<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n <span class=\"token punctuation\">}</span>\n</code></pre>\n<p> 继续查看 <code>_barrier.waitFor</code> 方法</p>\n<pre class=\" language-java\"><code class=\"language-java\"> <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> timeout<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> TimeUnit units<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> AlertException<span class=\"token punctuation\">,</span> InterruptedException <span class=\"token punctuation\">{</span>\n     <span class=\"token function\">checkAlert</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token keyword\">return</span> waitStrategy<span class=\"token punctuation\">.</span><span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">,</span> cursorSequence<span class=\"token punctuation\">,</span> dependentSequences<span class=\"token punctuation\">,</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">,</span> timeout<span class=\"token punctuation\">,</span> units<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n <span class=\"token punctuation\">}</span>\n</code></pre>\n<p>Disruptor Queue 为消费者提供了若干种消息等待策略</p>\n<ul>\n<li><code>BlockingWaitStrategy</code>：阻塞等待，CPU 占用小，但是会切换线程，延迟较高</li>\n<li><code>BusySpinWaitStrategy</code>：自旋等待，CPU 占用高，但是无需切换线程，延迟低</li>\n<li><code>YieldingWaitStrategy</code>：先自旋等待，然后使用 Thread.yield() 唤醒其他线程，CPU 占用和延迟比较均衡</li>\n<li><code>SleepingWaitStrategy</code>：先自旋，然后<code>Thread.yield()</code>，最后调用 <code>LockSupport.parkNanos(1L)</code>，CPU 占用和延迟比较均衡</li>\n</ul>\n<p>Storm 的默认等待策略为 <code>BlockingWaitStrategy</code>。<code>BlockingWaitStrategy</code> 的 <code>waitFor</code> 函数实现如下</p>\n<pre class=\" language-java\"><code class=\"language-java\"> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>availableSequence <span class=\"token operator\">=</span> cursor<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         lock<span class=\"token punctuation\">.</span><span class=\"token function\">lock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n             <span class=\"token operator\">++</span>numWaiters<span class=\"token punctuation\">;</span>\n             <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>availableSequence <span class=\"token operator\">=</span> cursor<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                 barrier<span class=\"token punctuation\">.</span><span class=\"token function\">checkAlert</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                 <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>processorNotifyCondition<span class=\"token punctuation\">.</span><span class=\"token function\">await</span><span class=\"token punctuation\">(</span>timeout<span class=\"token punctuation\">,</span> sourceUnit<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                     <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n                 <span class=\"token punctuation\">}</span>\n             <span class=\"token punctuation\">}</span>\n         <span class=\"token punctuation\">}</span>\n         <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n             <span class=\"token operator\">--</span>numWaiters<span class=\"token punctuation\">;</span>\n             lock<span class=\"token punctuation\">.</span><span class=\"token function\">unlock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         <span class=\"token punctuation\">}</span>\n <span class=\"token punctuation\">}</span>\n</code></pre>\n<p> <code>BlockingWaitStrategy</code> 内部使用信号量来阻塞 Consumer，当 await 超时后，Consumer 线程会被自动唤醒，继续循环查询可用消息。</p>\n</li>\n<li>而<code>DisruptorQueue.consumeBatchWhenAvailable</code> 方法中可以看到，Storm 此处设置超时为 10ms。推测在没有消息或者消息量较少时，Executor 在消费队列时会被阻塞，由于超时时间很短，工作线程会频繁超时，<code>consumeBatchWhenAvailable</code> 会被频繁调用，导致 CPU 占用飙高。尝试将 10ms 修改成 100ms，编译 Storm 后重新部署集群，使用 Storm 的 demo 拓扑，将 bolt 并发度调到 1000，修改 spout 代码为 10s 发一条消息。经测试 CPU 占用大幅减少。再将 100ms 改成 1s，测试 CPU 占用基本降为零。</li>\n<li><p>但是随着调高超时，测试时并没有发现消息处理有延时。继续查看 <code>BlockingWaitStrategy</code> 代码，发现 Disruptor Queue 的 Producer 在写入消息后会唤醒等待的 Consumer。</p>\n<pre class=\" language-java\"><code class=\"language-java\"> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span> <span class=\"token operator\">!=</span> numWaiters<span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">{</span>\n     lock<span class=\"token punctuation\">.</span><span class=\"token function\">lock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token keyword\">try</span>\n     <span class=\"token punctuation\">{</span>\n         processorNotifyCondition<span class=\"token punctuation\">.</span><span class=\"token function\">signalAll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token punctuation\">}</span>\n     <span class=\"token keyword\">finally</span>\n     <span class=\"token punctuation\">{</span>\n         lock<span class=\"token punctuation\">.</span><span class=\"token function\">unlock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token punctuation\">}</span>\n <span class=\"token punctuation\">}</span>\n</code></pre>\n<p> 这样，Storm 的 10ms 超时就很奇怪了，没有减少消息延时，反而增加了系统负载。带着这个疑问查看代码的上下文，发现在构造 <code>DisruptorQueue</code> 对象时有这么一句注释</p>\n<pre class=\" language-clojure\"><code class=\"language-clojure\"> ;; :block strategy requires using a timeout on waitFor (implemented in DisruptorQueue), as sometimes the consumer stays blocked even when there's an item on the queue.\n (defnk disruptor-queue\n     [^String queue-name buffer-size :claim-strategy :multi-threaded :wait-strategy :block]\n     (DisruptorQueue. queue-name\n                 ((CLAIM-STRATEGY claim-strategy) buffer-size)\n                 (mk-wait-strategy wait-strategy)))\n</code></pre>\n<p> Storm 使用的 Disruptor Queue 版本为2.10.1。查看 Disruptor Queue 的change log，发现该版本的 <code>BlockingWaitStrategy</code> 有潜在的并发问题，可能导致某条消息在写入时没有唤醒等待的消费者。</p>\n<blockquote>\n<p>2.10.2 Released (21-Aug-2012)</p>\n<ul>\n<li>Bug fix, potential race     condition in BlockingWaitStrategy.</li>\n<li>Bug fix set initial     SequenceGroup value to -1 (Issue     #27).</li>\n<li>Deprecate timeout methods that will be removed in version 3.</li>\n</ul>\n</blockquote>\n<p> 因此 Storm 使用了短超时，这样在出现并发问题时，没有被唤醒的消费方也会很快因为超时重新查询可用消息，防止出现消息延时。 这样如果直接修改超时到 1000ms，一旦出现并发问题，最坏情况下消息会延迟 1000ms。在权衡性能和延时之后，我们在 Storm 的配置文件中增加配置项来修改超时参数。这样使用者可以自己选择保证低延时还是低 CPU 占用率。</p>\n</li>\n<li>就 <code>BlockingWaitStrategy</code> 的潜在并发问题咨询了Disruptor Queue的作者，得知2.10.4版本已经修复了这个并发问题（<a href=\"https://github.com/LMAX-Exchange/disruptor/issues/119\" target=\"_blank\" rel=\"noopener\">Race condition in 2.10.1 release</a> ）。将 Storm 依赖升级到此版本。但是对 Disruptor Queue 的 2.10.1 做了并发测试，无法复现这个并发问题，因此也无法确定 2.10.4 是否彻底修复。谨慎起见，在升级依赖的同时保留了之前的超时配置项，并将默认超时调整为 1000ms。经测试，在集群空闲时 CPU 占用正常，并且压测也没有出现消息延时。</li>\n</ol>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>关于集群空闲CPU反而飙高的问题，已经向Storm社区提交PR并且已被接受 <a href=\"https://github.com/apache/storm/pull/630\" target=\"_blank\" rel=\"noopener\">[STORM-935] Update Disruptor queue version to 2.10.4</a>。在线业务流量通常起伏很大，如果被这个问题困扰，可以考虑应用此 patch。</li>\n<li>Storm UI 中可以看到很多有用的信息，但是缺乏记录，最好对其进行二次开发（或者直接读取 ZooKeeper 中信息），记录每个时间段的数据，方便分析集群和拓扑运行状况。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>最近将公司的在线业务迁移到 Storm 集群上，上线后遇到低峰期 CPU 耗费严重的情况。在解决问题的过程中深入了解了 Storm 的内部实现原理，并且解决了一个 Storm 0.9-0.10版本一直存在的严重 bug，目前代码已经合并到了 Storm 新版本中，在这篇文章里会介绍这个问题出现的场景、分析思路、解决的方式和一些个人的收获。</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>首先简单介绍一下 Storm，老司机可以直接跳过这段。 Storm 是 Twitter 开源的一个大数据处理框架，专注于流式数据的处理。Storm通过创建拓扑结构（Topology）来转换数据流。和 Hadoop 的作业（Job）不同，Topology 会持续转换数据，除非被集群关闭。 下图是一个简单的 Storm Topology 结构图。</p>\n<p><img src=\"/images/storm.gif\" alt=\"topology\"></p>\n<p>可以看出Topology是由不同组件（Component）串/并联形成的有向图。数据元组（Tuple）会在Component之间通过数据流的形式进行有向传递。Component有两种</p>\n<ul>\n<li>Spout：Tuple 来源节点，持续不断的产生Tuple，形成数据流</li>\n<li>Bolt：Tuple 处理节点，处理收到的 Tuple，如果有需要，也可以生成新的 Tuple 传递到其他 Bolt</li>\n</ul>\n<p>目前业界主要在离线或者对实时性要求不高业务中使用 Storm。随着 Storm 版本的更迭，可靠性和实时性在逐渐增强，已经有运行在线业务的能力。因此我们尝试将一些实时性要求在百毫秒级的在线业务迁入Storm 集群。</p>\n<h2 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h2><ol>\n<li>某次高峰时，Storm 上的一个业务拓扑频繁出现消息处理延迟。延时达到了 10s 甚至更高。查看高峰时的物理机指标监控，CPU、内存和 IO 都有很大的余量。判断是随着业务增长，服务流量逐渐增加，某个 Bolt 之前设置的并行度不够，导致消息堆积了。</li>\n<li>临时增加该 Bolt 并行度，解决了延迟的问题，但是第二天的低峰期，服务突然报警，CPU 负载过高，达到了 100%。</li>\n</ol>\n<h2 id=\"排查\"><a href=\"#排查\" class=\"headerlink\" title=\"排查\"></a>排查</h2><ol>\n<li><p>用 Top 看了下 CPU 占用，系统调用占用了 70% 左右。再用 <a href=\"https://github.com/qdaxb/wtool\" target=\"_blank\" rel=\"noopener\">wtool</a> 对 Storm 的工作进程进行分析，找到了 CPU 占用最高的线程</p>\n<pre><code class=\"java\"> java.lang.Thread.State: TIMED_WAITING (parking)\n at sun.misc.Unsafe.park(Native Method)\n - parking to wait for  &lt;0x0000000640a248f8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)\n at com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:87)\n at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:54)\n at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:97)\n at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80)\n at backtype.storm.daemon.executor$fn__3441$fn__3453$fn__3500.invoke(executor.clj:748)\n at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463)\n at clojure.lang.AFn.run(AFn.java:24)\n at java.lang.Thread.run(Thread.java:745)\n</code></pre>\n<p> 我们可以看到这些线程都在信号量上等待。调用的来源是 <code>disruptor$consume_batch_when_available</code>。</p>\n</li>\n<li><p>disruptor 是 Storm 内部消息队列的封装。所以先了解了一下 Storm 内部的消息传输机制。</p>\n<p> <img src=\"/images/storm-messaging.png\" alt=\"Storm内部消息传输机制\">（图片来源<a href=\"http://www.michael-noll.com/blog/2013/06/21/understanding-storm-internal-message-buffers/\" target=\"_blank\" rel=\"noopener\">Understanding the Internal Message Buffers of Storm</a>）</p>\n<p> Storm 的工作节点称为 Worker（其实就是一个JVM 进程）。不同 Worker 之间通过 Netty（旧版 Storm 使用 ZeroMQ）进行通讯。每个Worker 内部包含一组 Executor。Storm 会为拓扑中的每个 Component 都分配一个 Executor。在实际的数据处理流程中，数据以消息的形式在 Executor 之间流转。Executor 会循环调用绑定的 Component 的处理方法来处理收到的消息。 Executor 之间的消息传输使用队列作为消息管道。Storm 会给每个 Executor 分配两个队列和两个处理线程。</p>\n<ul>\n<li>工作线程：读取接收队列，对消息进行处理，如果产生新的消息，会写入发送队列</li>\n<li>发送线程：读取发送队列，将消息发送其他Executor</li>\n</ul>\n<p>当Executor的发送线程发送消息时，会判断目标Executor是否在同一Worker内，如果是，则直接将消息写入目标Executor的接收队列，如果不是，则将消息写入Worker的传输队列，通过网络发送。 Executor工作/发送线程读取队列的代码如下，这里会循环调用consume-batch-when-available读取队列中的消息，并对消息进行处理。</p>\n<pre><code class=\"clojure\"> (async-loop\n   (fn []\n     ...\n     (disruptor/consume-batch-when-available receive-queue event-handler)\n   ...\n ))\n</code></pre>\n</li>\n<li><p>我们再来看一下 <code>consume_batch_when_available</code> 这个函数里做了什么。</p>\n<pre><code class=\"clojure\"> (defn consume-batch-when-available\n   [^DisruptorQueue queue handler]\n   (.consumeBatchWhenAvailable queue handler))\n</code></pre>\n<p> 前面提到 Storm 使用队列作为消息管道。Storm 作为流式大数据处理框架，对消息传输的性能很敏感，因此使用了高效内存队列 Disruptor Queue 作为消息队列。</p>\n<p> <img src=\"/images/storm-simple.png\" alt=\"storm-simple\"></p>\n<p> Disruptor Queue 是 LMAX 开源的一个无锁内存队列。内部实现如下。</p>\n<p> <img src=\"/images/Models.png\" alt=\"Disruptor queue\"><br> （图片来源 <a href=\"https://github.com/LMAX-Exchange/disruptor/wiki/Introduction\" target=\"_blank\" rel=\"noopener\">Disruptor queue Introduction</a>)</p>\n<p> Disruptor Queue 通过 Sequencer 来管理队列，Sequencer 内部使用 RingBuffer 存储消息。RingBuffer 中消息的位置使用 Sequence 表示。队列的生产消费过程如下</p>\n<ul>\n<li>Sequencer 使用一个 Cursor 来保存写入位置。</li>\n<li>每个 Consumer 都会维护一个消费位置，并注册到 Sequencer。</li>\n<li>Consumer 通过 SequenceBarrier 和 Sequencer 进行交互。Consumer 每次消费时，SequenceBarrier 会比较消费位置和 Cursor 来判断是否有可用消息：如果没有，<strong>会按照设定的策略等待消息</strong>；如果有，则读取消息，修改消费位置。</li>\n<li>Producer 在写入前会查看所有消费者的消费位置，在有可用位置时会写入消息，更新 Cursor。</li>\n</ul>\n<p>查看 <code>DisruptorQueue.consumeBatchWhenAvailable</code> 实现如下</p>\n<pre><code class=\"java\"> final long nextSequence = _consumer.get() + 1;\n final long availableSequence = _barrier.waitFor(nextSequence, 10, TimeUnit.MILLISECONDS);\n if (availableSequence &gt;= nextSequence) {\n     consumeBatchToCursor(availableSequence, handler);\n }\n</code></pre>\n<p> 继续查看 <code>_barrier.waitFor</code> 方法</p>\n<pre><code class=\"java\"> public long waitFor(final long sequence, final long timeout, final TimeUnit units) throws AlertException, InterruptedException {\n     checkAlert();\n     return waitStrategy.waitFor(sequence, cursorSequence, dependentSequences, this, timeout, units);\n }\n</code></pre>\n<p>Disruptor Queue 为消费者提供了若干种消息等待策略</p>\n<ul>\n<li><code>BlockingWaitStrategy</code>：阻塞等待，CPU 占用小，但是会切换线程，延迟较高</li>\n<li><code>BusySpinWaitStrategy</code>：自旋等待，CPU 占用高，但是无需切换线程，延迟低</li>\n<li><code>YieldingWaitStrategy</code>：先自旋等待，然后使用 Thread.yield() 唤醒其他线程，CPU 占用和延迟比较均衡</li>\n<li><code>SleepingWaitStrategy</code>：先自旋，然后<code>Thread.yield()</code>，最后调用 <code>LockSupport.parkNanos(1L)</code>，CPU 占用和延迟比较均衡</li>\n</ul>\n<p>Storm 的默认等待策略为 <code>BlockingWaitStrategy</code>。<code>BlockingWaitStrategy</code> 的 <code>waitFor</code> 函数实现如下</p>\n<pre><code class=\"java\"> if ((availableSequence = cursor.get()) &lt; sequence) {\n         lock.lock();\n         try {\n             ++numWaiters;\n             while ((availableSequence = cursor.get()) &lt; sequence) {\n                 barrier.checkAlert();\n\n                 if (!processorNotifyCondition.await(timeout, sourceUnit)) {\n                     break;\n                 }\n             }\n         }\n         finally {\n             --numWaiters;\n             lock.unlock();\n         }\n }\n</code></pre>\n<p> <code>BlockingWaitStrategy</code> 内部使用信号量来阻塞 Consumer，当 await 超时后，Consumer 线程会被自动唤醒，继续循环查询可用消息。</p>\n</li>\n<li>而<code>DisruptorQueue.consumeBatchWhenAvailable</code> 方法中可以看到，Storm 此处设置超时为 10ms。推测在没有消息或者消息量较少时，Executor 在消费队列时会被阻塞，由于超时时间很短，工作线程会频繁超时，<code>consumeBatchWhenAvailable</code> 会被频繁调用，导致 CPU 占用飙高。尝试将 10ms 修改成 100ms，编译 Storm 后重新部署集群，使用 Storm 的 demo 拓扑，将 bolt 并发度调到 1000，修改 spout 代码为 10s 发一条消息。经测试 CPU 占用大幅减少。再将 100ms 改成 1s，测试 CPU 占用基本降为零。</li>\n<li><p>但是随着调高超时，测试时并没有发现消息处理有延时。继续查看 <code>BlockingWaitStrategy</code> 代码，发现 Disruptor Queue 的 Producer 在写入消息后会唤醒等待的 Consumer。</p>\n<pre><code class=\"java\"> if (0 != numWaiters)\n {\n     lock.lock();\n     try\n     {\n         processorNotifyCondition.signalAll();\n     }\n     finally\n     {\n         lock.unlock();\n     }\n }\n</code></pre>\n<p> 这样，Storm 的 10ms 超时就很奇怪了，没有减少消息延时，反而增加了系统负载。带着这个疑问查看代码的上下文，发现在构造 <code>DisruptorQueue</code> 对象时有这么一句注释</p>\n<pre><code class=\"clojure\"> ;; :block strategy requires using a timeout on waitFor (implemented in DisruptorQueue), as sometimes the consumer stays blocked even when there&#39;s an item on the queue.\n (defnk disruptor-queue\n     [^String queue-name buffer-size :claim-strategy :multi-threaded :wait-strategy :block]\n     (DisruptorQueue. queue-name\n                 ((CLAIM-STRATEGY claim-strategy) buffer-size)\n                 (mk-wait-strategy wait-strategy)))\n</code></pre>\n<p> Storm 使用的 Disruptor Queue 版本为2.10.1。查看 Disruptor Queue 的change log，发现该版本的 <code>BlockingWaitStrategy</code> 有潜在的并发问题，可能导致某条消息在写入时没有唤醒等待的消费者。</p>\n<blockquote>\n<p>2.10.2 Released (21-Aug-2012)</p>\n<ul>\n<li>Bug fix, potential race     condition in BlockingWaitStrategy.</li>\n<li>Bug fix set initial     SequenceGroup value to -1 (Issue     #27).</li>\n<li>Deprecate timeout methods that will be removed in version 3.</li>\n</ul>\n</blockquote>\n<p> 因此 Storm 使用了短超时，这样在出现并发问题时，没有被唤醒的消费方也会很快因为超时重新查询可用消息，防止出现消息延时。 这样如果直接修改超时到 1000ms，一旦出现并发问题，最坏情况下消息会延迟 1000ms。在权衡性能和延时之后，我们在 Storm 的配置文件中增加配置项来修改超时参数。这样使用者可以自己选择保证低延时还是低 CPU 占用率。</p>\n</li>\n<li>就 <code>BlockingWaitStrategy</code> 的潜在并发问题咨询了Disruptor Queue的作者，得知2.10.4版本已经修复了这个并发问题（<a href=\"https://github.com/LMAX-Exchange/disruptor/issues/119\" target=\"_blank\" rel=\"noopener\">Race condition in 2.10.1 release</a> ）。将 Storm 依赖升级到此版本。但是对 Disruptor Queue 的 2.10.1 做了并发测试，无法复现这个并发问题，因此也无法确定 2.10.4 是否彻底修复。谨慎起见，在升级依赖的同时保留了之前的超时配置项，并将默认超时调整为 1000ms。经测试，在集群空闲时 CPU 占用正常，并且压测也没有出现消息延时。</li>\n</ol>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>关于集群空闲CPU反而飙高的问题，已经向Storm社区提交PR并且已被接受 <a href=\"https://github.com/apache/storm/pull/630\" target=\"_blank\" rel=\"noopener\">[STORM-935] Update Disruptor queue version to 2.10.4</a>。在线业务流量通常起伏很大，如果被这个问题困扰，可以考虑应用此 patch。</li>\n<li>Storm UI 中可以看到很多有用的信息，但是缺乏记录，最好对其进行二次开发（或者直接读取 ZooKeeper 中信息），记录每个时间段的数据，方便分析集群和拓扑运行状况。</li>\n</ol>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjqo1fwqj00002kfyt5wjvjrw","category_id":"cjqo1fwqp00012kfyukm1pocr","_id":"cjqo1fwqs00042kfya9qijn4b"},{"post_id":"cjqo1fwv600092kfytoi5eahp","category_id":"cjqo1fwqp00012kfyukm1pocr","_id":"cjqo1fwvd000c2kfysgc2ecff"},{"post_id":"cjqo1fwv9000a2kfydoucrhhi","category_id":"cjqo1fwqp00012kfyukm1pocr","_id":"cjqo1fwve000d2kfyztvqelfr"}],"PostTag":[{"post_id":"cjqo1fwqj00002kfyt5wjvjrw","tag_id":"cjqo1fwqq00022kfyv1201wbq","_id":"cjqo1fwqs00062kfyffjxt3w6"},{"post_id":"cjqo1fwqj00002kfyt5wjvjrw","tag_id":"cjqo1fwqr00032kfyn0yj98nt","_id":"cjqo1fwqt00072kfy02kngezt"},{"post_id":"cjqo1fwqj00002kfyt5wjvjrw","tag_id":"cjqo1fwqs00052kfyrgf53g0r","_id":"cjqo1fwqt00082kfy7czu59xo"},{"post_id":"cjqo1fwv600092kfytoi5eahp","tag_id":"cjqo1fwqr00032kfyn0yj98nt","_id":"cjqo1fwvf000f2kfy98ua6bh4"},{"post_id":"cjqo1fwv600092kfytoi5eahp","tag_id":"cjqo1fwvc000b2kfyuacp60s7","_id":"cjqo1fwvf000g2kfyqlqabna8"},{"post_id":"cjqo1fwv9000a2kfydoucrhhi","tag_id":"cjqo1fwve000e2kfyc3qryj7m","_id":"cjqo1fwvf000h2kfykrrhxe0e"}],"Tag":[{"name":"DNS","_id":"cjqo1fwqq00022kfyv1201wbq"},{"name":"Docker","_id":"cjqo1fwqr00032kfyn0yj98nt"},{"name":"Problem","_id":"cjqo1fwqs00052kfyrgf53g0r"},{"name":"Swarm","_id":"cjqo1fwvc000b2kfyuacp60s7"},{"name":"Storm","_id":"cjqo1fwve000e2kfyc3qryj7m"}]}}