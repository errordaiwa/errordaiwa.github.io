<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Rick&#39;s lab">
<meta property="og:url" content="http://errordaiwa.github.io/index.html">
<meta property="og:site_name" content="Rick&#39;s lab">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Rick&#39;s lab">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://errordaiwa.github.io/">





  <title>Rick's lab</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Rick's lab</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">c-137</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://errordaiwa.github.io/2018/08/09/xxl-job-e7-9b-91-e6-8e-a7-e8-af-af-e6-8a-a5-e8-ad-a6-e9-97-ae-e9-a2-98-e6-8e-92-e6-9f-a5-e8-bf-87-e7-a8-8b/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xingyu Su">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rick's lab">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/09/xxl-job-e7-9b-91-e6-8e-a7-e8-af-af-e6-8a-a5-e8-ad-a6-e9-97-ae-e9-a2-98-e6-8e-92-e6-9f-a5-e8-bf-87-e7-a8-8b/" itemprop="url">DNS 配置有误导致监控误报的问题排查</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-09T12:58:33+08:00">
                2018-08-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul>
<li><a href="https://github.com/xuxueli/xxl-job" target="_blank" rel="noopener">XXL-Job</a> 是一套开源的任务调度框架，目前服务端部署了一套 XXL-Job 服务，用于监控线上服务质量</li>
<li>由于 Ucloud 出现过几次内网域名服务器故障，我们在 XXL-Job 中增加了定时任务监控第三方域名连通状态，并报警到钉钉群</li>
</ul>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ul>
<li>添加三方域名报警之后，钉钉群中经常收到报警，但是实际观察时，发现服务并无问题，报警为误报</li>
</ul>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><ul>
<li><p>查看报警对应的执行脚本，核心代码如下</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ping -c 5 target.com</span><br><span class="line">if (($? == 0))</span><br><span class="line">then</span><br><span class="line">    //正常</span><br><span class="line">else</span><br><span class="line">    //报警</span><br><span class="line">    exit 1;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看报警对应的脚本执行日志，发现如下报错</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping: unknown host</span><br></pre></td></tr></table></figure>
</li>
<li><p>初步判断是域名解析有问题导致报警，使用 <code>dig</code> 和 <code>nslookup</code> 查看域名解析情况，结果正常返回。由于报警也是偶发，觉得可能是域名解析偶发失败导致 <code>ping</code> 命令报错</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[work@monitor01 ~]$ nslookup    target.com</span><br><span class="line">Server:       10.9.255.1</span><br><span class="line">Address:  10.9.255.1#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">Name: target.com</span><br><span class="line">Address: xx.xx.xx.xx</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 XXL-Job 部署的机器上尝试复现问题，脚本如下。执行脚本，直到有报警时停止，查看日志，没有失败的情况</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while true</span><br><span class="line">do</span><br><span class="line">  echo "`date`============"</span><br><span class="line">  ping -c1 target.com</span><br><span class="line">  echo "result: $?"</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 XXL-Job 机器上观察 XXL-Job 进程，使用 <code>ps -elf</code> 命令追踪父进程。发现进程是运行在 Docker 容器中的</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work@monitor01 ~]$ ps -elf |    grep 31525</span><br><span class="line">0 S root     31525  1689  0  80      0 - 86935 futex_ Jun29 ?           00:16:10    /usr/bin/docker-containerd-shim    current    6b0f5c6aa2f52318867466a32774071    f7bbf540779ef92bb16ccf00494c6c5    /var/run/docker/libcontainerd/6    0f5c6aa2f52318867466a327740711f    bbf540779ef92bb16ccf00494c6c5e    /usr/libexec/docker/docker-runc-current</span><br></pre></td></tr></table></figure>
</li>
<li><p>容器和宿主机的网络环境是隔离的，所以 XXL-Job 报警时，宿主机上的脚本没有复现问题。于是在容器中继续执行脚本，尝试复现问题</p>
</li>
<li><p>脚本执行几分钟后，在日志中观察到有报错的情况。这里注意到，报错的地方似乎花费的时间比较久</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Mon Jul  2 08:30:35 UTC     2018============</span><br><span class="line">ping: unknown host</span><br><span class="line">result: 1</span><br><span class="line">Mon Jul  2 08:30:37 UTC     2018============</span><br></pre></td></tr></table></figure>
</li>
<li><p>对脚本进行调整，记录调用时间</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time ping -c1 target.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>重新执行脚本，发现报错时，<code>ping</code> 命令的调用花费了一秒左右的时间。感觉可能是 DNS 解析超时了。</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Mon Jul  2 09:43:12 UTC     2018============</span><br><span class="line">ping: unknown host</span><br><span class="line"></span><br><span class="line">real    0m1.049s</span><br><span class="line">user    0m0.002s</span><br><span class="line">sys     0m0.002s</span><br><span class="line">result: 1</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看容器 DNS 解析配置</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@f9c78250c2a0:~# cat        /etc/resolv.conf</span><br><span class="line">search xxx.com</span><br><span class="line">nameserver 127.0.0.11</span><br><span class="line">options timeout:1 attempts:1        rotate single-request-reopen        ndots:0</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过 <code>man resolv.conf</code> 查阅 <code>resolv.conf</code> 参数的含义。发现容器内的 DNS 解析超时时间配置成了一秒，并且只尝试一次。DNS 使用 UDP 协议传输数据。UDP 协议设计上就是不可靠的，所以会存在丢包的情况，而且 DNS 解析需要去公网域名服务器请求数据，延迟也有不确定性。当 DNS 解析失败时，<code>ping</code> 命令就会报错，进而触发报警。</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">timeout:n</span><br><span class="line">  Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server.  Measured in seconds, the  default is RES_TIMEOUT (currently 5, see &lt;resolv.h&gt;).  The value for this option is silently capped to 30.</span><br><span class="line"></span><br><span class="line">attempts:n</span><br><span class="line">  Sets  the  number  of  times  the resolver will send a query to its name servers before giving up and returning an error to the calling application.  The default is RES_DFLRETRY (currently 2, see &lt;resolv.h&gt;).  The value for this option is silently capped to 5.</span><br></pre></td></tr></table></figure>
</li>
<li><p>问题到这里基本定位完成，开始尝试解决问题。查阅 Docker 官方文档中关于<a href="https://docs.docker.com/config/containers/container-networking/#dns-services" target="_blank" rel="noopener">网络的配置</a>，发现可以通过 <code>dns_opt</code> 参数配置容器的 DNS 解析配置</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--dns-opt A key-value pair representing a DNS option and its value. See your operating system’s documentation for resolv.conf for valid options.</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改容器配置，将 DNS 解析超时设置为 2s，重试一次。重启服务，观察半个小时，不再出现误报，问题解决</p>
  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dns_opt:</span></span><br><span class="line"><span class="attr">  - timeout:</span><span class="number">2</span></span><br><span class="line"><span class="attr">  - attempts:</span><span class="number">2</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">single-request</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">rotate</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h2><p>容器和宿主机 DNS 解析配置不同，导致容器内 ping 命令调用偶发失败，引发报警误报。通过 <code>dns_opt</code> 参数修改容器 DNS 超时时间和重试次数后，问题解决。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://errordaiwa.github.io/2016/12/14/docker-swarm-mode/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xingyu Su">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rick's lab">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/14/docker-swarm-mode/" itemprop="url">小试 Docker swarm mode</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-14T18:12:37+08:00">
                2016-12-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近在公司尝试将测试环境 docker 化，由于组件比较多，考虑引入容器编排方案。首先尝试使用 docker-compose 来管理各个组件实例。可以跑通基本逻辑，但是目前没有服务发现框架，只能使用 docker 内置网络中的 DNS 发现其它服务，这限定了测试环境只能跑在单机环境上，时间久了各种 OOM。最近看到 docker 新版本附带的 swarm mode，尝试搭建了一套多机 docker 环境，感觉很满足当前的需求，并且对代码基本零侵入。简单的记录了一下搭建过程以及一些注意事项。</p>
<h2 id="Swarm-mode-简介"><a href="#Swarm-mode-简介" class="headerlink" title="Swarm mode 简介"></a>Swarm mode 简介</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>docker swarm 是 docker 官方编排项目之一，提供将多个 docker engine 实例变成一台虚拟 docker engine 实例的能力，便于 docker 容器集群管理</li>
<li>docker 1.12 版本推出了 swarm mode 功能，将 docker swarm 深度集成到 docker engine 中，提供了整套更为简洁的 api 对 swarm 集群进行管理。相对于原生的 docker swarm，swarm mode 部署更为简单，无需外置的服务发现框架，并且提供了容器路由服务</li>
</ul>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul>
<li>Node: node 是 swarm 集群中一个 docker engine 实例<ul>
<li>Manager node: 对整体集群进行管理和编排，并维护整个集群</li>
<li>Worker node: 接收 manager node 分配的 tasks，并运行，默认情况下，manager node 本身也作为一个 worker node 运行 task，可以通过改变配置让 manager node 变成一个 manager-only 的纯管理节点</li>
</ul>
</li>
<li>Task: swarm 集群任务的基本单元，通常是一个 docker container 的实例</li>
<li>Service: 由一组同类型 task 聚合而成，是 swarm 集群中主要操作对象</li>
<li>Load balancing: swarm 集群有一套内置的负载均衡策略提供外部访问到目标容器的路由，在创建 Service 时可以发布端口到外部网络上，访问 swarm 集群任意节点该端口的请求都会被路由到该 Service</li>
</ul>
<h2 id="Swarm-mode-quick-start"><a href="#Swarm-mode-quick-start" class="headerlink" title="Swarm mode quick start"></a>Swarm mode quick start</h2><h3 id="初始化-swarm-集群"><a href="#初始化-swarm-集群" class="headerlink" title="初始化 swarm 集群"></a>初始化 swarm 集群</h3><ol>
<li>初始化机器，安装 docker-engine （版本需要高于 1.12）</li>
<li><p>选择一台机器作为 swarm manager 节点，在 console 中运行 <code>docker swarm init</code> 创建 swarm 集群，命令会返回加入集群的命令</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Swarm initialized: current node     (c8dzd8xek2c9csoxj27ycl1nh) is     now a manager.</span><br><span class="line"></span><br><span class="line">To add a worker to this swarm,     run the following command:</span><br><span class="line"></span><br><span class="line">    docker swarm join \</span><br><span class="line">    --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \</span><br><span class="line">    192.168.65.2:2377</span><br><span class="line"></span><br><span class="line">To add a manager to this swarm,     run 'docker swarm join-token     manager' and follow the     instructions.</span><br></pre></td></tr></table></figure>
</li>
<li><p>在另一台机器上，运行提示中的命令加入集群，如果没有保存之前的提示，可以通过 <code>docker swarm join-token worker</code> 查询</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker swarm join \</span><br><span class="line">    --token SWMTKN-1-07bc8loetz13sy5eqv2t1uycqfr9dqabsd7x08gr22w7gj79fc-eiz5ljflasv65rnoq36aj2mfc \</span><br><span class="line">    192.168.65.2:2377</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 manager 节点上运行 <code>docker info</code> 可以看到 swarm 集群的信息</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Swarm: active</span><br><span class="line"> NodeID: c8dzd8xek2c9csoxj27ycl1nh</span><br><span class="line"> Is Manager: true</span><br><span class="line"> ClusterID: cj75fozp5effsiyuuq2dixv95</span><br><span class="line"> Managers: 1</span><br><span class="line"> Nodes: 2</span><br><span class="line"> Orchestration:</span><br><span class="line">  Task History Retention Limit: 5</span><br><span class="line"> Raft:</span><br><span class="line">  Snapshot Interval: 10000</span><br><span class="line">  Heartbeat Tick: 1</span><br><span class="line">  Election Tick: 3</span><br><span class="line"> Dispatcher:</span><br><span class="line">  Heartbeat Period: 5 seconds</span><br><span class="line"> CA Configuration:</span><br><span class="line">  Expiry Duration: 3 months</span><br><span class="line"> Node Address: 192.168.65.2</span><br></pre></td></tr></table></figure>
</li>
<li><p>在节点上运行 <code>docker swarm leave</code> 可以让当前节点离开集群，如果是管理节点，需要增加 <code>--force</code> 参数</p>
</li>
</ol>
<h3 id="创建一个-service"><a href="#创建一个-service" class="headerlink" title="创建一个 service"></a>创建一个 service</h3><ol>
<li>在 manager 节点上运行命令 <code>docker service create --replicas 1 --name redis docker-registry-cn.easemob.com/redis</code>创建 redis 服务, <code>replicas</code> 参数指定该服务中的 task 数量<ul>
<li>如果是私有 registry，需要在 manager 节点上执行 <code>docker login</code>，然后创建服务时，增加 <code>--with-registry-auth</code> 参数将认证信息发送到 worker 节点</li>
</ul>
</li>
<li><p>在 manager 节点上运行 <code>docker service ls</code> 查看所有服务状态</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ID            NAME   REPLICAS      IMAGE                                     COMMAND</span><br><span class="line">0nqfp11n2xgb  redis  1/1           docker-registry-cn.easemob.    com/redis</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 manager 节点上运行 <code>docker service ps redis</code> 查看 redis 服务状态</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ID                         NAME     IMAGE                                 NODE  DESIRED STATE  CURRENT STATE         ERROR</span><br><span class="line">3qpkmxptn8o336h161183a0vz  redis.1  docker-registry-cn.easemob.com/redis  moby  Running        Running 17 hours ago</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 manager 节点上运行 <code>docker service update redis</code> 更新服务。例如可以用 <code>docker service update redis --publish-add 6379:6379</code> 发布 redis 服务到 swarm 集群 6379 端口上（也可以在创建服务时使用 –publish 参数发布），在 swarm 任意节点上运行 <code>redis-cli</code> 都可以连接到 redis 服务</p>
</li>
<li>在 manager 节点上运行 <code>docker service rm redis</code> 可以删除服务</li>
</ol>
<h3 id="Service-间网络调用"><a href="#Service-间网络调用" class="headerlink" title="Service 间网络调用"></a>Service 间网络调用</h3><ul>
<li><p>如果 service publish 了端口，可以通过任意 swarm 节点 publish 端口进行调用</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker service update     --publish-add 6379:6379 redis1</span><br><span class="line">redis1</span><br><span class="line">➜  ~ telnet localhost 6379</span><br><span class="line">Trying ::1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is '^]'.</span><br><span class="line">set test aaa</span><br><span class="line">+OK</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建一个 overlay 的网络，创建服务时，通过 <code>--network</code> 参数连接到 overlay 网络上。通过内建的 DNS 服务，可以通过 service name 解析出 task IP</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker network create --driver overlay --subnet 10.0.10.0/24 sandbox</span><br><span class="line">e7q4c68ybbw7xhrkb0at47k00</span><br><span class="line">➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis1  docker-registry-cn.easemob.com/redis</span><br><span class="line">0dfqszxp925id4ma9blolyjmz</span><br><span class="line">➜  ~ docker service create --with-registry-auth --replicas 1 --network sandbox --name redis2  docker-registry-cn.easemob.com/redis</span><br><span class="line">c3khd0snpu13ixx8popuoludx</span><br><span class="line">➜  ~ docker ps</span><br><span class="line">CONTAINER ID        IMAGE                                         COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">4c92e01d25fd        docker-registry-cn.easemob.com/redis:latest   "/entrypoint.sh redis"   12 seconds ago      Up 9 seconds        6379/tcp            redis2.1.4qbw5c0hawat5rr50hgzpxj7l</span><br><span class="line">c60b4659e768        docker-registry-cn.easemob.com/redis:latest   "/entrypoint.sh redis"   6 minutes ago       Up 6 minutes        6379/tcp            redis1.1.4pvn93a6i2n5teou41mddmlxr</span><br><span class="line">➜  ~ docker exec -it c60b4659e768 /bin/bash</span><br><span class="line">root@c60b4659e768:/data# ping redis2</span><br><span class="line">PING redis2 (10.0.10.4): 56 data bytes</span><br><span class="line">64 bytes from 10.0.10.4: icmp_seq=0 ttl=64 time=0.109 ms</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="一些坑点"><a href="#一些坑点" class="headerlink" title="一些坑点"></a>一些坑点</h3><ul>
<li>截止 docker 最新版本（1.12.3），在 overlay 网络中，以 VIP 方式启动的服务，可以解析 DNS，但是无法 <code>ping</code> IP，某些依赖 <code>ping</code> 检查网络连通的程序会有问题，见 <a href="https://github.com/docker/docker/issues/25497" target="_blank" rel="noopener">https://github.com/docker/docker/issues/25497</a>。解决方案是启动模式换成 dnsrr （创建服务时增加参数 –endpoint-mode dnsrr），或者使用 tasks.${service_name} 的方式调用</li>
<li>在某些操作系统（例如 Suse）上，service publish 的端口无法连接，原因不明，可能和缺少某些内核模块有关。建议使用 Centos7</li>
<li>swarm manager 会在 service 中 task 退出时重新提交 task，某些需要一次性运行的 docker image （例如环境初始化脚本的执行）endpoint 或者 cmd 需要修改成 block 形式，以免退出后被重复提交。Docker 1.13 版本允许 <code>docker run</code> 启动的容器 attach 到 swarm service 使用的 network 上，可以将一次性运行的 image 直接以 <code>docker run</code> 的方式启动</li>
<li><code>docker service update --image myimage:latest</code> 不会拉取新镜像，即使远端有更新的版本，只能通过手动拉取镜像后重启 service 来更新服务。这个 bug 会在 docker 1.13 上被修复</li>
</ul>
<p>Have fun :)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://errordaiwa.github.io/2015/07/18/storm-cpu-overload/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xingyu Su">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rick's lab">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/07/18/storm-cpu-overload/" itemprop="url">Storm 在线业务实践-集群空闲 CPU 飙高问题排查</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2015-07-18T17:51:53+08:00">
                2015-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近将公司的在线业务迁移到 Storm 集群上，上线后遇到低峰期 CPU 耗费严重的情况。在解决问题的过程中深入了解了 Storm 的内部实现原理，并且解决了一个 Storm 0.9-0.10版本一直存在的严重 bug，目前代码已经合并到了 Storm 新版本中，在这篇文章里会介绍这个问题出现的场景、分析思路、解决的方式和一些个人的收获。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>首先简单介绍一下 Storm，老司机可以直接跳过这段。 Storm 是 Twitter 开源的一个大数据处理框架，专注于流式数据的处理。Storm通过创建拓扑结构（Topology）来转换数据流。和 Hadoop 的作业（Job）不同，Topology 会持续转换数据，除非被集群关闭。 下图是一个简单的 Storm Topology 结构图。</p>
<p><img src="/images/storm.gif" alt="topology"></p>
<p>可以看出Topology是由不同组件（Component）串/并联形成的有向图。数据元组（Tuple）会在Component之间通过数据流的形式进行有向传递。Component有两种</p>
<ul>
<li>Spout：Tuple 来源节点，持续不断的产生Tuple，形成数据流</li>
<li>Bolt：Tuple 处理节点，处理收到的 Tuple，如果有需要，也可以生成新的 Tuple 传递到其他 Bolt</li>
</ul>
<p>目前业界主要在离线或者对实时性要求不高业务中使用 Storm。随着 Storm 版本的更迭，可靠性和实时性在逐渐增强，已经有运行在线业务的能力。因此我们尝试将一些实时性要求在百毫秒级的在线业务迁入Storm 集群。</p>
<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><ol>
<li>某次高峰时，Storm 上的一个业务拓扑频繁出现消息处理延迟。延时达到了 10s 甚至更高。查看高峰时的物理机指标监控，CPU、内存和 IO 都有很大的余量。判断是随着业务增长，服务流量逐渐增加，某个 Bolt 之前设置的并行度不够，导致消息堆积了。</li>
<li>临时增加该 Bolt 并行度，解决了延迟的问题，但是第二天的低峰期，服务突然报警，CPU 负载过高，达到了 100%。</li>
</ol>
<h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><ol>
<li><p>用 Top 看了下 CPU 占用，系统调用占用了 70% 左右。再用 <a href="https://github.com/qdaxb/wtool" target="_blank" rel="noopener">wtool</a> 对 Storm 的工作进程进行分析，找到了 CPU 占用最高的线程</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">java.lang.Thread.State: TIMED_WAITING (parking)</span><br><span class="line">at sun.misc.Unsafe.park(Native Method)</span><br><span class="line">- parking to wait <span class="keyword">for</span>  &lt;<span class="number">0x0000000640a248f8</span>&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class="line">at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:<span class="number">215</span>)</span><br><span class="line">at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:<span class="number">2163</span>)</span><br><span class="line">at com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:<span class="number">87</span>)</span><br><span class="line">at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:<span class="number">54</span>)</span><br><span class="line">at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:<span class="number">97</span>)</span><br><span class="line">at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:<span class="number">80</span>)</span><br><span class="line">at backtype.storm.daemon.executor$fn__3441$fn__3453$fn__3500.invoke(executor.clj:<span class="number">748</span>)</span><br><span class="line">at backtype.storm.util$async_loop$fn__464.invoke(util.clj:<span class="number">463</span>)</span><br><span class="line">at clojure.lang.AFn.run(AFn.java:<span class="number">24</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></figure>
<p> 我们可以看到这些线程都在信号量上等待。调用的来源是 <code>disruptor$consume_batch_when_available</code>。</p>
</li>
<li><p>disruptor 是 Storm 内部消息队列的封装。所以先了解了一下 Storm 内部的消息传输机制。</p>
<p> <img src="/images/storm-messaging.png" alt="Storm内部消息传输机制">（图片来源<a href="http://www.michael-noll.com/blog/2013/06/21/understanding-storm-internal-message-buffers/" target="_blank" rel="noopener">Understanding the Internal Message Buffers of Storm</a>）</p>
<p> Storm 的工作节点称为 Worker（其实就是一个JVM 进程）。不同 Worker 之间通过 Netty（旧版 Storm 使用 ZeroMQ）进行通讯。每个Worker 内部包含一组 Executor。Storm 会为拓扑中的每个 Component 都分配一个 Executor。在实际的数据处理流程中，数据以消息的形式在 Executor 之间流转。Executor 会循环调用绑定的 Component 的处理方法来处理收到的消息。 Executor 之间的消息传输使用队列作为消息管道。Storm 会给每个 Executor 分配两个队列和两个处理线程。</p>
<ul>
<li>工作线程：读取接收队列，对消息进行处理，如果产生新的消息，会写入发送队列</li>
<li>发送线程：读取发送队列，将消息发送其他Executor</li>
</ul>
<p>当Executor的发送线程发送消息时，会判断目标Executor是否在同一Worker内，如果是，则直接将消息写入目标Executor的接收队列，如果不是，则将消息写入Worker的传输队列，通过网络发送。 Executor工作/发送线程读取队列的代码如下，这里会循环调用consume-batch-when-available读取队列中的消息，并对消息进行处理。</p>
 <figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">async-loop</span></span><br><span class="line">  (<span class="name"><span class="builtin-name">fn</span></span> []</span><br><span class="line">    ...</span><br><span class="line">    (<span class="name">disruptor/consume-batch-when-available</span> receive-queue event-handler)</span><br><span class="line">  ...</span><br><span class="line">))</span><br></pre></td></tr></table></figure>
</li>
<li><p>我们再来看一下 <code>consume_batch_when_available</code> 这个函数里做了什么。</p>
 <figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name"><span class="builtin-name">defn</span></span> consume-batch-when-available</span><br><span class="line">  [<span class="comment">^DisruptorQueue</span> queue handler]</span><br><span class="line">  (<span class="name">.consumeBatchWhenAvailable</span> queue handler))</span><br></pre></td></tr></table></figure>
<p> 前面提到 Storm 使用队列作为消息管道。Storm 作为流式大数据处理框架，对消息传输的性能很敏感，因此使用了高效内存队列 Disruptor Queue 作为消息队列。</p>
<p> <img src="/images/storm-simple.png" alt="storm-simple"></p>
<p> Disruptor Queue 是 LMAX 开源的一个无锁内存队列。内部实现如下。</p>
<p> <img src="/images/Models.png" alt="Disruptor queue"><br> （图片来源 <a href="https://github.com/LMAX-Exchange/disruptor/wiki/Introduction" target="_blank" rel="noopener">Disruptor queue Introduction</a>)</p>
<p> Disruptor Queue 通过 Sequencer 来管理队列，Sequencer 内部使用 RingBuffer 存储消息。RingBuffer 中消息的位置使用 Sequence 表示。队列的生产消费过程如下</p>
<ul>
<li>Sequencer使用一个Cursor来保存写入位置。</li>
<li>每个Consumer都会维护一个消费位置，并注册到Sequencer。</li>
<li>Consumer通过SequenceBarrier和Sequencer进行交互。Consumer每次消费时，SequenceBarrier会比较消费位置和Cursor来判断是否有可用消息：如果没有，<strong>会按照设定的策略等待消息</strong>；如果有，则读取消息，修改消费位置。</li>
<li>Producer在写入前会查看所有消费者的消费位置，在有可用位置时会写入消息，更新Cursor。</li>
</ul>
<p>查看 <code>DisruptorQueue.consumeBatchWhenAvailable</code> 实现如下</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">long</span> nextSequence = _consumer.get() + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">long</span> availableSequence = _barrier.waitFor(nextSequence, <span class="number">10</span>, TimeUnit.MILLISECONDS);</span><br><span class="line"><span class="keyword">if</span> (availableSequence &gt;= nextSequence) &#123;</span><br><span class="line">    consumeBatchToCursor(availableSequence, handler);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 继续查看 <code>_barrier.waitFor</code> 方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">waitFor</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> sequence, <span class="keyword">final</span> <span class="keyword">long</span> timeout, <span class="keyword">final</span> TimeUnit units)</span> <span class="keyword">throws</span> AlertException, InterruptedException </span>&#123;</span><br><span class="line">    checkAlert();</span><br><span class="line">    <span class="keyword">return</span> waitStrategy.waitFor(sequence, cursorSequence, dependentSequences, <span class="keyword">this</span>, timeout, units);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Disruptor Queue 为消费者提供了若干种消息等待策略</p>
<ul>
<li><code>BlockingWaitStrategy</code>：阻塞等待，CPU 占用小，但是会切换线程，延迟较高</li>
<li><code>BusySpinWaitStrategy</code>：自旋等待，CPU 占用高，但是无需切换线程，延迟低</li>
<li><code>YieldingWaitStrategy</code>：先自旋等待，然后使用 Thread.yield() 唤醒其他线程，CPU 占用和延迟比较均衡</li>
<li><code>SleepingWaitStrategy</code>：先自旋，然后<code>Thread.yield()</code>，最后调用 <code>LockSupport.parkNanos(1L)</code>，CPU 占用和延迟比较均衡</li>
</ul>
<p>Storm 的默认等待策略为 <code>BlockingWaitStrategy</code>。<code>BlockingWaitStrategy</code> 的 <code>waitFor</code> 函数实现如下</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ((availableSequence = cursor.get()) &lt; sequence) &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ++numWaiters;</span><br><span class="line">            <span class="keyword">while</span> ((availableSequence = cursor.get()) &lt; sequence) &#123;</span><br><span class="line">                barrier.checkAlert();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!processorNotifyCondition.await(timeout, sourceUnit)) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span> &#123;</span><br><span class="line">            --numWaiters;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> <code>BlockingWaitStrategy</code> 内部使用信号量来阻塞 Consumer，当 await 超时后，Consumer 线程会被自动唤醒，继续循环查询可用消息。</p>
</li>
<li>而<code>DisruptorQueue.consumeBatchWhenAvailable</code> 方法中可以看到，Storm 此处设置超时为 10ms。推测在没有消息或者消息量较少时，Executor 在消费队列时会被阻塞，由于超时时间很短，工作线程会频繁超时，<code>consumeBatchWhenAvailable</code> 会被频繁调用，导致 CPU 占用飙高。尝试将 10ms 修改成 100ms，编译 Storm 后重新部署集群，使用 Storm 的 demo 拓扑，将 bolt 并发度调到 1000，修改 spout 代码为 10s 发一条消息。经测试 CPU 占用大幅减少。再将 100ms 改成 1s，测试 CPU 占用基本降为零。</li>
<li><p>但是随着调高超时，测试时并没有发现消息处理有延时。继续查看 <code>BlockingWaitStrategy</code> 代码，发现 Disruptor Queue 的 Producer 在写入消息后会唤醒等待的 Consumer。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="number">0</span> != numWaiters)</span><br><span class="line">&#123;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        processorNotifyCondition.signalAll();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">finally</span></span><br><span class="line">    &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 这样，Storm 的 10ms 超时就很奇怪了，没有减少消息延时，反而增加了系统负载。带着这个疑问查看代码的上下文，发现在构造 <code>DisruptorQueue</code> 对象时有这么一句注释</p>
 <figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">;; :block strategy requires using a     timeout on waitFor (implemented in DisruptorQueue), as sometimes the consumer stays blocked even when there's an item on the queue.</span></span><br><span class="line">(<span class="name">defnk</span> disruptor-queue</span><br><span class="line">    [<span class="comment">^String</span> queue-name buffer-size <span class="symbol">:claim-strategy</span> <span class="symbol">:multi-threaded</span> <span class="symbol">:wait-strategy</span> <span class="symbol">:block</span>]</span><br><span class="line">    (<span class="name">DisruptorQueue.</span> queue-name</span><br><span class="line">                ((<span class="name">CLAIM-STRATEGY</span> claim-strategy) buffer-size)</span><br><span class="line">                (<span class="name">mk-wait-strategy</span> wait-strategy)))</span><br></pre></td></tr></table></figure>
<p> Storm 使用的 Disruptor Queue 版本为2.10.1。查看 Disruptor Queue 的change log，发现该版本的 <code>BlockingWaitStrategy</code> 有潜在的并发问题，可能导致某条消息在写入时没有唤醒等待的消费者。</p>
<blockquote>
<p>2.10.2 Released (21-Aug-2012)</p>
<ul>
<li>Bug fix, potential race     condition in BlockingWaitStrategy.</li>
<li>Bug fix set initial     SequenceGroup value to -1 (Issue     #27).</li>
<li>Deprecate timeout methods that will be removed in version 3.</li>
</ul>
</blockquote>
<p> 因此 Storm 使用了短超时，这样在出现并发问题时，没有被唤醒的消费方也会很快因为超时重新查询可用消息，防止出现消息延时。 这样如果直接修改超时到 1000ms，一旦出现并发问题，最坏情况下消息会延迟 1000ms。在权衡性能和延时之后，我们在 Storm 的配置文件中增加配置项来修改超时参数。这样使用者可以自己选择保证低延时还是低 CPU 占用率。</p>
</li>
<li>就 <code>BlockingWaitStrategy</code> 的潜在并发问题咨询了Disruptor Queue的作者，得知2.10.4版本已经修复了这个并发问题（<a href="https://github.com/LMAX-Exchange/disruptor/issues/119" target="_blank" rel="noopener">Race condition in 2.10.1 release</a> ）。将 Storm 依赖升级到此版本。但是对 Disruptor Queue 的 2.10.1 做了并发测试，无法复现这个并发问题，因此也无法确定 2.10.4 是否彻底修复。谨慎起见，在升级依赖的同时保留了之前的超时配置项，并将默认超时调整为 1000ms。经测试，在集群空闲时 CPU 占用正常，并且压测也没有出现消息延时。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>关于集群空闲CPU反而飙高的问题，已经向Storm社区提交PR并且已被接受 <a href="https://github.com/apache/storm/pull/630" target="_blank" rel="noopener">[STORM-935] Update Disruptor queue version to 2.10.4</a>。在线业务流量通常起伏很大，如果被这个问题困扰，可以考虑应用此 patch。</li>
<li>Storm UI 中可以看到很多有用的信息，但是缺乏记录，最好对其进行二次开发（或者直接读取 ZooKeeper 中信息），记录每个时间段的数据，方便分析集群和拓扑运行状况。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Xingyu Su</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xingyu Su</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
